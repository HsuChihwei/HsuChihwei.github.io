<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2017-10-16 The unit test and mock in python]]></title>
    <url>%2F2017%2F10%2F16%2F2017-10-16-The-unit-test-and-mock-in-python%2F</url>
    <content type="text"><![CDATA[mock 功效 完成功能测试123456789101112131415161718192021222324252627# module.pyclass Count(): def add(self, a, b): return a + b# test.pyfrom unittest import mockimport unittestfrom module import Countclass MockDemo(unittest.TestCase): def test_add(self): count = Count() count.add = mock.Mock(return_value=13, side_effect=count.add) # side_effect参数和return_value是相反的。它给mock分配了可替换的结果，覆盖了return_value。简单的说，一个模拟工厂调用将返回side_effect值，而不是return_value；所以，设置side_effect参数为Count类add()方法，那么return_value的作用失效。 result = count.add(8, 8) print(result) # 将会真正的调用add()方法，得到的返回值为16（8+8）。通过print打印结果。 count.add.assert_called_with(8, 8) # 检查mock方法是否获得了正确的参数。 self.assertEqual(result, 16)if __name__ == '__main__': unittest.main() 解决测试依赖 例如，我们要测试A模块，然后A模块依赖于B模块的调用。但是，由于B模块的改变，导致了A模块返回结果的改变，从而使A模块的测试用例失败。其实，对于A模块，以及A模块的用例来说，并没有变化，不应该失败才对。这个时候就是mock发挥作用的时候了。通过mock模拟掉影响A模块的部分（B模块）。至于mock掉的部分（B模块）应该由其它用例来测试。 add_and_multiply()函数依赖了multiply()函数的返回值123456789101112131415161718192021222324252627# function.pydef add_and_multiply(x, y): addition = x + y multiple = multiply(x, y) return (addition, multiple)def multiply(x, y): return x * y # test.pyimport unittestimport functionclass MyTestCase(unittest.TestCase): def test_add_and_multiply(self): x = 3 y = 5 addition, multiple = function.add_and_multiply(x, y) self.assertEqual(8, addition) self.assertEqual(15, multiple)if __name__ == "__main__": unittest.main() 修改multiply()函数的代码，这样测试会失败12def multiply(x, y): return x * y + 3 把 multiply()函数mock掉，解决依赖1234567891011121314151617181920212223import unittestfrom unittest.mock import patchimport functionclass MyTestCase(unittest.TestCase): @patch("function.multiply") # patch()装饰/上下文管理器可以很容易地模拟类或对象在模块测试。在测试过程中，您指定的对象将被替换为一个模拟（或其他对象），并在测试结束时还原。这里模拟function.py文件中multiply()函数。 def test_add_and_multiply2(self, mock_multiply): # 在定义测试用例中，将mock的multiply()函数（对象）重命名为 mock_multiply对象。 x = 3 y = 5 mock_multiply.return_value = 15 # 设定mock_multiply对象的返回值为固定的15。 addition, multiple = function.add_and_multiply(x, y) mock_multiply.assert_called_once_with(3, 5) # 检查mock_multiply方法的参数是否正确。 self.assertEqual(8, addition) self.assertEqual(15, multiple)if __name__ == "__main__": unittest.main() Mock attributes in Python mock?12with patch('requests.post') as patched_post: type(patched_post.return_value).ok = PropertyMock(return_value=True) Mock session in requests library？123456789101112131415161718192021222324252627282930313233343536373839404142# main.pyimport requestsdef do_session_get(): session = requests.session() return session.get('foo').status_code# tests.pyimport unittestimport mockfrom main import do_session_get# The module of we mock, return the exact data that we expecteddef mocked_requests(*args, **kwargs): # print args class MockResponse(object): def __init__(self, status_code, text, json_data=None, content=None): self.json_data = json_data self.status_code = status_code self.text = text self.content = content def json(self): return self.json_data if args[0] == 'foo': return MockResponse(200, 'success') elif args[0] == 'http://someurl.com/': return MockResponse(200, 'success') return MockResponse(404, '-1')# from main import do_session_getclass TestDoSessionGet(unittest.TestCase): @mock.patch('requests.session') def test_should_mock_session_get(self, mocked_session): mocked_session.return_value = mock.MagicMock(get=mock.MagicMock(side_effect=mocked_requests)) # print do_session_get() self.assertEqual(do_session_get(), 200)if __name__ == '__main__': unittest.main() assert 常用断言速查 项目 举例 assertEqual(a, b) a == b assertNotEqual(a, b) a != b assertGreater(a, b) a &gt; b assertGreaterEqual(a, b) a &gt;= b assertLess(a, b) a &lt; b assertLessEqual(a, b) a &lt;= b assertTrue(x) bool(x) is True assertFalse(x) bool(x) is False assertIs(a, b) a is b assertIsNot(a, b) a is not b assertIsNone(x) x is None assertIsNotNone(x) x is not None assertIn(a, b) a in b assertNotIn(a, b) a not in b assertIsInstance(a, b) isinstance(a, b) assertNotIsInstance(a, b) not isinstance(a, b) 干货：mock模板（requests）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# common_test.py# -*- coding: utf-8 -*-import unittestimport mockimport requests"""If the module is import from others files, like:from my.great.package import FlowTypeThen, we should do this, below:# Now we must patch 'my.great.package.requests.get'@mock.patch('my.great.package.requests.get', side_effect=mocked_requests)instead of "@mock.patch('common_test.requests.get', side_effect=mocked_requests)"because the requests module was imported in that file"""# The module that need unittestclass FlowType(object): def __init__(self): pass def flow_type(self): url = 'http://chihweihsu.com/' resp = requests.get(url) return resp# The data of we mockmock_status_code = 200mock_text = 'You are my sunshine!'mock_json = &#123;'data': 'You are my sunshine!'&#125;mock_content = 'You are my sunshine!'# The module of we mock, return the exact data that we expecteddef mocked_requests(*args, **kwargs): class MockResponse(object): def __init__(self, status_code, text, json_data=None, content=None): self.json_data = json_data self.status_code = status_code self.text = text self.content = content def json(self): return self.json_data if args[0] == 'http://chihweihsu.com/': return MockResponse(mock_status_code, mock_text, json_data=mock_json, content=mock_content) elif args[0] == 'http://someurl.com/': return MockResponse(200, 'success') return MockResponse(404, '-1')# The whole test case moduleclass TestCommon(unittest.TestCase): def setUp(self): pass # We patch 'common_test.requests.get' with our own method. The mock object is passed in to our test case method. @mock.patch('common_test.requests.get', side_effect=mocked_requests) def test_flow_type(self, mocked_get): f = FlowType() resp = f.flow_type() self.assertIsNotNone(resp) self.assertEqual(resp.status_code, mock_status_code) self.assertIs(resp.text, mock_text) self.assertIn(resp.content, mock_content) self.assertDictEqual(resp.json(), mock_json) self.assertIsInstance(resp.json(), dict)if __name__ == '__main__': unittest.main()]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>unittest</tag>
        <tag>mock</tag>
        <tag>单元测试</tag>
        <tag>挡板</tag>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-10-16 描述统计学笔记（Udacity）]]></title>
    <url>%2F2017%2F10%2F16%2F2017-10-16-%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E7%AC%94%E8%AE%B0%EF%BC%88Udacity%EF%BC%89%2F</url>
    <content type="text"><![CDATA[how would you measure memory? maybe can ask some question like what’s food you eat yesterday,2 days ago, 5 days ago, 10days ago… give you a article,test how much time you take to keep in mind the whole article give you 1 hours, test how many words that you keep in mind ###]]></content>
      <categories>
        <category>数据分析</category>
        <category>描述统计学</category>
      </categories>
      <tags>
        <tag>统计学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-9-28 Python 编码之禅]]></title>
    <url>%2F2017%2F09%2F28%2F2017-9-28-Python-%E7%BC%96%E7%A0%81%E4%B9%8B%E7%A6%85%2F</url>
    <content type="text"><![CDATA[情景描述： 平时工作中经常碰到编码、解码、乱码……类似的问题不胜其烦，如街边小广告一般异常讨厌，需要花时间好好整理一番，“一”绝后患。 str(s)与unicode(s) str(s)和unicode(s)是两个工厂方法，分别返回str字符串对象和unicode字符串对象；str(s)是s.encode(‘ascii’)的简写；unicode(s)是s.decode(‘ascii’)的简写； 123456789101112131415161718192021222324252627282930313233strstr(object='')str(object=b'', encoding='utf-8', errors='strict')object - object whose informal representation is to be returnedencoding - Defaults of UTF-8. Encoding of the given objecterrors - response when decoding fails. There are six types of error response： strict - default response which raises a UnicodeDecodeError exception on failure ignore - ignores the unencodable unicode from the result replace - replaces the unencodable unicode to a question mark ? xmlcharrefreplace - inserts XML character reference instead of unencodable unicode backslashreplace - inserts a \uNNNN espace sequence instead of unencodable unicode namereplace - inserts a \N&#123;...&#125; escape sequence instead of unencodable unicode&gt;&gt;&gt; s3 = u"你好" &gt;&gt;&gt; s3 u'\u4f60\u597d' &gt;&gt;&gt; str(s3) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)上面s3是unicode类型的字符串，str(s3)相当于是执行s3.encode(‘ascii’)因为“你好”两个汉字不能用ascii码来表示，所以就报错了，指定正确的编码：s3.encode(‘gbk’)或者s3.encode("utf-8")就不会出现这个问题了。类似的unicode有同样的错误：&gt;&gt;&gt; s4 = "你好" &gt;&gt;&gt; unicode(s4) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xc4 in position 0: ordinal not in range(128) unicode(s4)等效于s4.decode(‘ascii’)，因此要正确的转换就要正确指定其编码s4.decode(‘gbk’)或者s4.decode("utf-8")。 ### 1234567891011121314151617181920212223242526In [20]: '中文'Out[20]: '\xe4\xb8\xad\xe6\x96\x87'In [21]: u'中文'Out[21]: u'\u4e2d\u6587'In [29]: print '中文'中文In [30]: print u'中文'中文In [34]: print '\u4e2d\u6587'\u4e2d\u6587In [35]: print u'\u4e2d\u6587'中文In [26]: u'中文'.encode('gb2312')Out[26]: '\xd6\xd0\xce\xc4'In [27]: u'中文'.encode('gbk')Out[27]: '\xd6\xd0\xce\xc4'In [28]: u'中文'.encode('utf8')Out[28]: '\xe4\xb8\xad\xe6\x96\x87' 问题：1234567In [41]: '中文'.encode('utf8')---------------------------------------------------------------------------UnicodeDecodeError Traceback (most recent call last)&lt;ipython-input-41-94bb800b6371&gt; in &lt;module&gt;()----&gt; 1 '中文'.encode('utf8')UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128) 解决办法：123import sysreload(sys)sys.setdefaultencoding('utf-8')]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>decode</tag>
        <tag>encode</tag>
        <tag>总结</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-9-14 通过__slots__节省内存]]></title>
    <url>%2F2017%2F09%2F14%2F2017-9-14-%E9%80%9A%E8%BF%87-slots-%E8%8A%82%E7%9C%81%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[见原文1234567class Measurement: __slots__ = ['x', 'y', 'val'] def __init__(self, x, y, value): self.x = x self.y = y self.val = value merge dict merged_dict1dict_merged = &#123;**a, **b, **c&#125;]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>内存</tag>
        <tag>slots</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-9-12 str() vs json.dumps()]]></title>
    <url>%2F2017%2F09%2F12%2F2017-9-12-str-vs-json-dumps%2F</url>
    <content type="text"><![CDATA[str() 与 json.dumps()的区别1234567891011121314151617&gt;&gt;&gt; data = &#123;'jsonKey': 'jsonValue',"title": "hello world"&#125;&gt;&gt;&gt; print json.dumps(data)&#123;"jsonKey": "jsonValue", "title": "hello world"&#125;&gt;&gt;&gt; print str(data)&#123;'jsonKey': 'jsonValue', 'title': 'hello world'&#125;&gt;&gt;&gt; json.dumps(data)'&#123;"jsonKey": "jsonValue", "title": "hello world"&#125;'&gt;&gt;&gt; str(data)"&#123;'jsonKey': 'jsonValue', 'title': 'hello world'&#125;" In fact, I am more interested in their difference in single quote and double quote in output strings. It seems that I already know one difference between them (mentioned above) and whether json.loads() can load the output string. json.dumps() is much more than just making a string out of a Python object, it would always produce a valid JSON string (assuming everything inside the object is serializable) following the Type Conversion Table. For instance, if one of the values is None, the str() would produce an invalid JSON which cannot be loaded: 12345678910111213&gt;&gt;&gt; data = &#123;'jsonKey': None&#125;&gt;&gt;&gt; str(data)"&#123;'jsonKey': None&#125;"&gt;&gt;&gt; json.loads(str(data))Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/__init__.py", line 338, in loads return _default_decoder.decode(s) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/decoder.py", line 366, in decode obj, end = self.raw_decode(s, idx=_w(s, 0).end()) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/decoder.py", line 382, in raw_decode obj, end = self.scan_once(s, idx)ValueError: Expecting property name: line 1 column 2 (char 1) But the dumps() would convert None into null making a valid JSON string that can be loaded: 123456&gt;&gt;&gt; import json&gt;&gt;&gt; data = &#123;'jsonKey': None&#125;&gt;&gt;&gt; json.dumps(data)'&#123;"jsonKey": null&#125;'&gt;&gt;&gt; json.loads(json.dumps(data))&#123;u'jsonKey': None&#125; In fact in (I believe most) implementations of Python, str(object) wraps strings in single quotes, which is not valid JSON. 12345678910An example:In [17]: print str(&#123;"a": 1&#125;)&#123;'a': 1&#125;str(boolean) is also not valid JSON:In [18]: print str(True)True__str__, can, however, be overridden in user defined classes to ensure that objects return JSON representations of themselves. 字典转字符串（dict to str）12345678910111213141516# If your dictionary isn't too big maybe str + eval can do the work:dict1 = &#123;'one':1, 'two':2, 'three': &#123;'three.1': 3.1, 'three.2': 3.2 &#125;&#125;str1 = str(dict1)dict2 = eval(str1)print dict1==dict2# You can use ast.literal_eval instead of eval for additional security if the source is untrusted.import json# convert to stringinput = json.dumps(&#123;'id': id &#125;)# load to dictmy_dict = json.loads(input) 字符串转字典（str to dict）1234# str to dictIn [33]: import astIn [34]: ast.literal_eval("&#123;'x':1, 'y':2&#125;")Out[34]: &#123;'x': 1, 'y': 2&#125; 转换已转义的字符串转字典（str to dict） 123456789&gt;&gt;&gt; a = '&#123;\\"name\\":\\"michael\\"&#125;'&gt;&gt;&gt; print a&#123;\"name\":\"michael\"&#125;&gt;&gt;&gt; type(json.loads('“' + a + '”'))&lt;type 'unicode'&gt;&gt;&gt;&gt; type(json.loads(json.loads('“' + a + '”')))&lt;type 'dict'&gt;# 第一次json.loads是将里面的\"这样的字符串转为"(只有一个双引号)，第二次再将其转为一个字典，记得不要漏掉前面先加双引号。 pymongo 根据ObjectId进行查询12from bson.objectid import ObjectId[i for i in dbm.neo_nodes.find(&#123;"_id": ObjectId(obj_id_to_find)&#125;)] float nan 12345678&gt;&gt;&gt; import math&gt;&gt;&gt; x=float('nan')&gt;&gt;&gt; math.isnan(x)True# The usual way to test for a NaN is to see if it's equal to itself, since nan isn't equal anything.def isNaN(num): return num != num]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>string</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-9-7 机器学习分类]]></title>
    <url>%2F2017%2F09%2F07%2F2017-9-7-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[机器学习： 线性回归 岭回归 LASSO 弹性网络 逻辑回归 Softmax 回归 决策树 ID3 C4.5 CART 神经网络 普通网络 CNN RNN GAN 架构总览： 数据仓库 SparkStreaming tensorflow scikit-learn模型库 django xgboost SparkMLLib特征库 redis numpy pandas]]></content>
      <categories>
        <category>Notes</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-9-7 机器学习路线]]></title>
    <url>%2F2017%2F09%2F07%2F2017-9-7-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[准备知识： 编程语言：Python，C++，Spark（大数据环境下）；知识储备：英语、线性代数、概率论、图论、神经科学。 第一步 统领大局： 建立大局观，是入门第一要务； 从宏观了解机器学习的全貌；机器学习：根据已有特征，选择模型，训练模型，预测未知数据；推荐书籍：-《图解机器学习》：通俗易懂，算法图解，入门必备；-《集体智慧编程》：代码实现，一个字“敲”；-《机器学习（周志华西瓜书）》：系统严谨，数学推导； 第二步 了解算法： 看遍所有算法原理，主要书籍：《机器学习（周志华）》；coursera 上Andrew NG的机器学习公开课，网易云也开了；邹博的《机器学习实战》；李沐《一起动手学习深度学习》；必学：线性回归，Logistics回归，决策树。 第三步 利用框架： 利用scikit-learn实现所学的算法（推荐鸢尾花分类、MNIST分类） 第四步 神经网络： 看懂Tensorflow官网demo：RNN、CNN、GAN；莫凡Tensorflow； 第五步 实操演练： 注册kangle，奋斗吧！上线一个小模型（django+scikit-learn） 第六步 关注落地： 机器学习MVP开发；针对小规模，有质量、已标注的数据进行训练；明确需求、特征量化、目标量化、特征清洗、模型选型、模型训练、线下验证、模型上线、特征清洗、模型预测、结果应用、运行监控； 实例一：客户动用率预测：1234567明确需求：与业务同事讨论本次需求的目标是什么，这里说的就是动用率预测；特征量化：选出可能有影响的特征，如：年龄，性别，近三个月是否动用等；目标量化：选择是否动用为目标；特征清洗：样本筛选，缺失值补全，利用先验知识去掉明显不符合常理的数据；模型选择：直接丢个逻辑回归试试看；模型训练：看训练集和测试集，讨论出一个精准度即可；模型上线：丢上线去跑跑看，看看结果，暂时不接入关键流程即可。 实例二：客户逾期率预测：1234567明确需求：与业务同事讨论本次需求的目标是什么，这里说的就是逾期率预测；特征量化：选出可能有影响的特征，如：年龄，性别，近三个月是否逾期等；目标量化：选择客户是否逾期作为目标；特征清洗：样本筛选，缺失值补全，利用先验知识去掉明显不符合常理的数据；模型选择：直接丢个softmax回归试试看；模型训练：看训练集和测试集，讨论出一个精准度即可；模型上线：丢上线去跑跑看，看看结果，暂时不接入关键流程即可。 实例三：客户风险级别预测：1234567明确需求：与业务同事讨论本次需求的目标是什么，这里说的就是风险级别预测；特征量化：选出可能有影响的特征，如：年龄，性别，近三个月是否逾期等；目标量化：选择预期风险等级作为目标；特征清洗：样本筛选，缺失值补全，利用先验知识去掉明显不符合常理的数据；模型选择：直接丢个决策树试试看；模型训练：看训练集和测试集，讨论出一个精准度即可；模型上线：丢上线去跑跑看，看看结果，暂时不接入关键流程即可。 第七步 补充数学： 《概率论与数理统计》陈希孺《线性代数应该这样学》 第八步 特征工程： 好的特征决是成功的一半；特征选择，特征清洗，决定模型的上限，算法和优化只是不断趋近这个上限；特征工程非常重要。 第九步 深入前沿： 深入了解前沿的底层原理阅读实践优秀论文，如：MapReduce原理的，李沐Parameter原理的，GAN原理的，LPA原理的…… 书单： 《深入浅出统计学》《深入浅出数据分析》《大数据智能》《深度学习》《优雅的理性》《创新者的窘境》《数学之美》]]></content>
      <categories>
        <category>Notes</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>路线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-9-5 计算体脂率]]></title>
    <url>%2F2017%2F09%2F05%2F2017-9-5-%E8%AE%A1%E7%AE%97%E4%BD%93%E8%84%82%E7%8E%87%2F</url>
    <content type="text"><![CDATA[情景描述： 用来计算一个人的体脂率 12345678910111213141516def get_BFR(weight, height, age, gender): """计算BMI及体脂率 :param weight: 体重（kg） :param height: 身高（m） :param age: 年龄（岁） :param gender: 性别（男--1，女--0） :returns: 体脂率，float """ # BMI BMI = weight /(height*height) # 体脂率 BFR = 1.2*BMI + 0.23*age - 5.4 - 10.8*gender return BFRget_BFR(55, 1.7, 26, 1)# 12.61737024221453]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-9-5 python list 排序 sort、sorted]]></title>
    <url>%2F2017%2F09%2F05%2F2017-9-5-python-list-%E6%8E%92%E5%BA%8F-sort%E3%80%81sorted%2F</url>
    <content type="text"><![CDATA[情景描述： 项目中，有一个list，list内部组成元素为dict，现需要根据dict中某个键的值来进行排序。 代码实现： reverse: False–默认，正序；True–逆序，由大到小； key: 可以根据key值自定义排序； sort与sorted区别: sortlist自身发生改变；sortedlist本身不发生改变。1234567891011121314151617181920212223242526272829303132333435363738394041424344a = [5,2,1,9,6] # sorted 用法&gt;&gt;&gt; sorted(a) #将a从小到大排序,不影响a本身结构 [1, 2, 5, 6, 9] &gt;&gt;&gt; sorted(a,reverse = True) #将a从大到小排序,不影响a本身结构 [9, 6, 5, 2, 1] # sort 用法&gt;&gt;&gt; a.sort() #将a从小到大排序,影响a本身结构 &gt;&gt;&gt; a [1, 2, 5, 6, 9] &gt;&gt;&gt; a.sort(reverse = True) #将a从大到小排序,影响a本身结构 &gt;&gt;&gt; a [9, 6, 5, 2, 1] # 注意，a.sort() 已改变其结构，b = a.sort() 是错误的写法! # 非数字排序&gt;&gt;&gt; b = ['aa','BB','bb','zz','CC'] &gt;&gt;&gt; sorted(b) ['BB', 'CC', 'aa', 'bb', 'zz'] #按列表中元素每个字母的ascii码从小到大排序,如果要从大到小,请用sorted(b,reverse=True)下同 # 根据key值自定义排序&gt;&gt;&gt; c =['CCC', 'bb', 'ffff', 'z'] &gt;&gt;&gt; sorted(c,key=len) #按列表的元素的长度排序 ['z', 'bb', 'CCC', 'ffff'] &gt;&gt;&gt; d =['CCC', 'bb', 'ffff', 'z'] &gt;&gt;&gt; sorted(d,key = str.lower ) #将列表中的每个元素变为小写，再按每个元素中的每个字母的ascii码从小到大排序 ['bb', 'CCC', 'ffff', 'z'] &gt;&gt;&gt; def lastchar(s): return s[-1] &gt;&gt;&gt; e = ['abc','b','AAz','ef'] &gt;&gt;&gt; sorted(e,key = lastchar) #自定义函数排序,lastchar为函数名，这个函数返回列表e中每个元素的最后一个字母 ['b', 'abc', 'ef', 'AAz'] #sorted(e,key=lastchar)作用就是 按列表e中每个元素的最后一个字母的ascii码从小到大排序 &gt;&gt;&gt; f = [&#123;'name':'abc','age':20&#125;,&#123;'name':'def','age':30&#125;,&#123;'name':'ghi','age':25&#125;] #列表中的元素为字典 &gt;&gt;&gt; def age(s): return s['age'] &gt;&gt;&gt; ff = sorted(f,key = age) #自定义函数按列表f中字典的age从小到大排序 [&#123;'age': 20, 'name': 'abc'&#125;, &#123;'age': 25, 'name': 'ghi'&#125;, &#123;'age': 30, 'name': 'def'&#125;] &gt;&gt;&gt; f2 = sorted(f,key = lambda x:x['age']) #如果觉得上面定义一个函数代码不美观，可以用lambda的形式来定义函数,效果[&#123;'age': 20, 'name': 'abc'&#125;, &#123;'age': 25, 'name': 'ghi'&#125;, &#123;'age': 30, 'name': 'def'&#125;]]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>list</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-31 自动 生成注释文档（docstring）]]></title>
    <url>%2F2017%2F08%2F31%2F2017-8-31-python-%E8%87%AA%E5%8A%A8-%E7%94%9F%E6%88%90%E6%B3%A8%E9%87%8A%E6%96%87%E6%A1%A3%EF%BC%88docstring%EF%BC%89%2F</url>
    <content type="text"><![CDATA[情景描述： 项目中，发现很多函数、类没有注释说明，一个个弄比较繁琐，所以…… docstring定义： 官方：A docstring is a string literal that occurs as the first statement in a module, function, class, or method definition. Such a docstring becomes the doc special attribute of that object；人话：“出现在模块、函数、类、方法里的第一个语句，就叫做docsting”；调用：使用__doc__。12345def foo(): """ This is function foo"""foo.__doc__# This is function foo docstring风格： 主要四种：javadoc(Epytext), reST, numpydoc, google 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# Epytext"""This is a javadoc style. @param param1: this is a first param@param param2: this is a second param@return: this is a description of what is returned@raise keyError: raises an exception"""# reST（推荐，reST风格，Sphinx的御用格式）"""This is a reST style. :param param1: this is a first param:param param2: this is a second param:returns: this is a description of what is returned:raises keyError: raises an exception"""# Google"""This is a groups style docs. Parameters: param1 - this is the first param param2 - this is a second param Returns: This is a description of what is returned Raises: KeyError - raises an exception"""# Numpydoc (Numpy风格)"""My numpydoc description of a kindof very exhautive numpydoc format docstring. Parameters----------first : array_like the 1st param name `first`second : the 2nd paramthird : &#123;'value', 'other'&#125;, optional the 3rd param, by default 'value' Returns-------string a value in a string Raises------KeyError when a key errorOtherError when an other error""" 转换工具pyment 用来创建、转换docsting，点击查看安装centos中可能使用不了patch，点击下载安装包pyment命令帮助：pyment -h 123456789101112# 安装pyment$ git clone https://github.com/dadadel/pyment.git # or git@github.com:dadadel/pyment.git$ cd pyment$ python setup.py install# 安装patch# 下载安装包：http://centos-packages.com/7/package/patch/rpm -i patch-2.7.1-8.el7.x86_64.rpm# 使用方法$ pyment test.py #生成patch$ patch -p1 &lt; test.py.patch #打patch 例子： 注释前123456789101112131415161718192021# test.pydef func(param1=True, param2='default val'): '''Description of func with docstring groups style. Params: param1 - descr of param1 that has True for default value. param2 - descr of param2 Returns: some value Raises: keyError: raises key exception TypeError: raises type exception ''' passclass A: def method(self, param1, param2=None): pass 执行pyment test.py，得到patch文件123456789101112131415161718192021222324252627282930313233343536373839# Patch generated by Pyment v0.2.0--- a/test.py+++ b/test.py@@ -1,20 +1,22 @@ def func(param1=True, param2=&apos;default val&apos;):- &apos;&apos;&apos;Description of func with docstring groups style.+ &quot;&quot;&quot;Description of func with docstring groups style.- Params:- param1 - descr of param1 that has True for default value.- param2 - descr of param2+ :param param1: descr of param1 that has True for default value+ :param param2: descr of param2 (Default value = &apos;default val&apos;)+ :returns: some value+ :raises keyError: raises key exception+ :raises TypeError: raises type exception- Returns:- some value-- Raises:- keyError: raises key exception- TypeError: raises type exception-- &apos;&apos;&apos;+ &quot;&quot;&quot; pass class A:+ &quot;&quot;&quot; &quot;&quot;&quot; def method(self, param1, param2=None):+ &quot;&quot;&quot;++ :param param1:+ :param param2: (Default value = None)++ &quot;&quot;&quot; pass 执行patch -p1 &lt; test.py.patch，注释后得到 12345678910111213141516171819202122def func(param1=True, param2='default val'): """Description of func with docstring groups style. :param param1: descr of param1 that has True for default value :param param2: descr of param2 (Default value = 'default val') :returns: some value :raises keyError: raises key exception :raises TypeError: raises type exception """ passclass A: """ """ def method(self, param1, param2=None): """ :param param1: :param param2: (Default value = None) """ pass 后续 使用sphinx的autodoc自动从docstring生产api文档, 避免重复工作，再娄一遍Api文档。]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Linux</tag>
        <tag>Docstring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-31 python two sum 问题]]></title>
    <url>%2F2017%2F08%2F31%2F2017-8-31-python-two-sum-%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[题目描述： 来自LeetCode 12345678910111213# Time: O(n)# Space: O(n)# Given an array of integers, return indices of the two numbers# such that they add up to a specific target.## You may assume that each input would have exactly one solution.## Example:# Given nums = [2, 7, 11, 15], target = 9,## Because nums[0] + nums[1] = 2 + 7 = 9,# return [0, 1]. Python 解法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110class Solution(object): def twoSum(self, nums, target): """ :type nums: List[int] :type target: int :rtype: List[int] """ lookup = &#123;&#125; for i, num in enumerate(nums): if target - num in lookup: return [lookup[target - num], i] lookup[num] = i return [] def twoSum2(self, nums, target): """ :type nums: List[int] :type target: int :rtype: List[int] """ k = 0 for i in nums: j = target - i k += 1 tmp_nums = nums[k:] if j in tmp_nums: return [k - 1, tmp_nums.index(j) + k]if __name__ == '__main__': print Solution().twoSum((2, 7, 11, 15), 9) # -*- coding: utf-8 -*-import timedef main(a, b): # med = a[int(len(a)/2)] c=[-1, -1] for i, v in enumerate(a): for j,k in enumerate(a[i+1:]): c = [i, i+j+1] if v+k==b else c return cdef main2(a, b): """ dict 存放查值 """ c = &#123;&#125; for i in range(len(a)): if b - a[i] in c: return [c[b-a[i]], i] c[a[i]] = i return [-1, -1]def sum_number(a, b): """ dict 存放差值 """ if len(a) &lt;= 1: return False c = &#123;&#125; for i in range(len(a)): if a[i] in c: return [c[a[i]], i] else: c[b - a[i]] = i return [-1, -1]def main3(a, b): for i in range(len(a)): if (b - a[len(a)-i-1]) in a[:len(a)-i-1]: return [a.index((b - a[len(a)-i-1])),len(a)-i-1] return [-1, -1]def main4(a, b): try: # print [[a.index((b - a[len(a)-i-1])),len(a)-i-1] for i in range(len(a)) if (b - a[len(a)-i-1]) in a[:len(a)-i-1]] return [[a.index((b - a[len(a)-i-1])),len(a)-i-1] for i in range(len(a)) if (b - a[len(a)-i-1]) in a[:len(a)-i-1]][0] except: return [-1,-1]def main5(a, b): return [[a.index((b - a[len(a)-i-1])),len(a)-i-1] for i in range(len(a)) if (b - a[len(a)-i-1]) in a[:len(a)-i-1]].pop()def main6(a, b): return [[a.index(b-j), i] for i,j in enumerate(a) if a.count(b-j) &gt; 0 and a.index(b-j)!=i].pop()if __name__ == '__main__': a = range(20) b = 18 # a = [49,1,2,3,50,51] # b=99 print 'list:&#123;&#125;,data:&#123;&#125;'.format(a,b) start = time.time() print main(a,b) print 'main_time_used:&#123;&#125;'.format(time.time()-start) start = time.time() print main2(a,b) print 'main2_time_used:&#123;&#125;'.format(time.time()-start) start = time.time() print main3(a,b) print 'main3_time_used:&#123;&#125;'.format(time.time()-start) start = time.time() print main4(a,b) print 'main4_time_used:&#123;&#125;'.format(time.time()-start) start = time.time() print main5(a,b) print 'main5_time_used:&#123;&#125;'.format(time.time()-start) start = time.time() print main6(a,b) print 'main6_time_used:&#123;&#125;'.format(time.time()-start)]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-28 python interval 区间处理]]></title>
    <url>%2F2017%2F08%2F28%2F2017-8-28-python-interval-%E5%8C%BA%E9%97%B4%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[1234567891011121314&gt;&gt;&gt; volume1 = Interval.between("A", "Foe")&gt;&gt;&gt; volume2 = Interval.between("Fog", "McAfee")&gt;&gt;&gt; volume3 = Interval.between("McDonalds", "Space")&gt;&gt;&gt; volume4 = Interval.between("Spade", "Zygote")&gt;&gt;&gt; encyclopedia = IntervalSet([volume1, volume2, volume3, volume4])&gt;&gt;&gt; mySet = IntervalSet([volume1, volume3, volume4])&gt;&gt;&gt; "Meteor" in encyclopediaTrue&gt;&gt;&gt; "Goose" in encyclopediaTrue&gt;&gt;&gt; "Goose" in mySetFalse&gt;&gt;&gt; volume2 in (encyclopedia ^ mySet)True 1234567a= 112 In [4]: a in range(300,400) ...: Out[4]: False In [5]: a in range(101,300) ...: Out[5]: True 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384python强大的区间处理库interval用法介绍原文发表在我的博客主页，转载请注明出处前言这个库是在阅读别人的源码的时候看到的，觉得十分好用，然而在网上找到的相关资料甚少，所以阅读了源码来做一个简单的用法总结。在网络的路由表中，经常会通过掩码来表示流表的匹配域，在python中有的时候为了方便的模拟流表的匹配过程，可以通过一个整数区间来表示诸如IP等的匹配范围，而本文介绍的库在区间处理上是十分的强大与方便。用法举例不论是在Linux系统还是Windows系统上，我们都可以方便的安装pip或者easy_install库来方便的安装大多数python库，interval也不例外。在这个库中提供了两个主要的类，分别是Interval和IntervalSet两个类。Interval类描述了一个连续的范围区间，这个区间可以是闭、开、半闭半开、无穷的，他的区间值不一定是数字，可以包含任何的数据类型，比如字符串，时间等等，同时他和python的各种操作（&lt;, &lt;=, ==, &gt;=, &gt;等）也是兼容的。IntervalSet包含了一个或多个互不相交的Interval集合。下面的这几个例子是源码中的。 &gt;&gt;&gt;volume1 = Interval.between("A", "Foe")&gt;&gt;&gt;volume2 = Interval.between("Fog", "McAfee")&gt;&gt;&gt;volume3 = Interval.between("McDonalds", "Space")&gt;&gt;&gt;volume4 = Interval.between("Spade", "Zygote")&gt;&gt;&gt;encyclopedia = IntervalSet([volume1, volume2, volume3, volume4])&gt;&gt;&gt;mySet = IntervalSet([volume1, volume3, volume4])&gt;&gt;&gt;"Meteor" in encyclopediaTrue&gt;&gt;&gt;"Goose" in encyclopediaTrue&gt;&gt;&gt;"Goose" in mySetFalse&gt;&gt;&gt;volume2 in (encyclopedia ^ mySet)True前面的三个例子比较容易理解，最后一个例子中，encyclopedia的区别就是mySet多了一个volume2，而异或就是将两个集合中相同的元素去掉，不同的元素保留，所以最后只剩下了volume2。除了字符串，利用interval还可以很方便的处理时间，下面的例子同样来自于源码。 &gt;&gt;&gt;officeHours = IntervalSet.between("08:00", "17:00")&gt;&gt;&gt;myLunch = IntervalSet.between("11:30", "12:30")&gt;&gt;&gt;myHours = IntervalSet.between("08:30", "19:30") - myLunch&gt;&gt;&gt;myHours.issubset(officeHours)False&gt;&gt;&gt;"12:00" in myHoursFalse&gt;&gt;&gt;"15:30" in myHoursTrue&gt;&gt;&gt;inOffice = officeHours &amp; myHours&gt;&gt;&gt;print inOffice['08:30'..'11:30'),('12:30'..'17:00']&gt;&gt;&gt;overtime = myHours - officeHours&gt;&gt;&gt;print overtime('17:00'..'19:30']在前言中说道interval库可以处理IP地址，简单的列举应用如下： # codingr1 = IntervalSet([Interval(1, 1000), Interval(1100, 1200)])r2 = IntervalSet([Interval(30, 50), Interval(60, 200), Interval(1150, 1300)])r3 = IntervalSet([Interval(1000, 3000)])r4 = IntervalSet([Interval(1000, 3000)])r5 = IntervalSet([Interval(30000, 12000)])print (r3 - r4), (r4 - r3), r3 &amp; r4print len(IntervalSet.empty())if r3 &amp; r4 == r4: print 'yes'print r3 &amp; r4if (r3 - r4).empty(): print "true"print (r3 - r4).empty()# output&lt;Empty&gt; &lt;Empty&gt; [1000..3000]0yes[1000..3000]&lt;Empty&gt;常用方法interval对象初始化参数（lower_bound=-Inf, upper_bound=Inf, **kwargs）三个boolean参数closed,lower_closed,upper_closed分表表示全闭，左闭右开，左开右闭。比如：r = Interval(upper_bound=62, closed=False)between(a, b, closed=True)：返回以a和b为界的区间less_than(a)：小于a的所有值构成interval，类似的还有less_than_or_equal_to，greater_than，greater_than_or_equal_to函数join(other)：将两个连续的intervals组合起来overlaps(other)：两个区间是否有重叠adjacent_to(other)：两个区间是否不重叠的毗邻总结是一篇总结文章，并没有什么深度，只是为了不再重复造轮子，在必要的时候一个库可以极大的提高效率。MeasureMeasure]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>区间</tag>
        <tag>interval</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-28 Pandas agg 使用lambda]]></title>
    <url>%2F2017%2F08%2F28%2F2017-8-28-Pandas-agg-%E4%BD%BF%E7%94%A8lambda%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819import numpy as npimport pandas as pdN = 100data = pd.DataFrame(&#123; 'type': np.random.randint(10, size=N), 'status': np.random.randint(10, size=N), 'name': np.random.randint(10, size=N), 'value': np.random.randint(10, size=N),&#125;)reading = np.random.random(10,)data = data.groupby(['type', 'status', 'name'])['value'].agg(&#123; 'one' : np.mean, 'two' : lambda value: 100* ((value&gt;32).sum() / reading.mean()), 'test2': lambda value: 100* ((value &gt; 45).sum() / value.mean())&#125;)print(data) 获取一列数据中最大值`pythonIn [34]: df.loc[df[‘Value’].idxmax()]Out[34]:Country USPlace KansasValue 894Name: 7 df = df.reset_index() data.groupby([‘Country’,’Place’])[‘Value’].max().item() df.groupby([‘country’,’place’], as_index=False)[‘value’].max() df.groupby(“country”).apply(lambda df:df.irow(df.value.argmax())) In [5]: df = pandas.DataFrame(np.random.randn(10,3),columns=[‘A’,’B’,’C’]) In [6]: dfOut[6]: A B C0 2.001289 0.482561 1.5799851 -0.991646 -0.387835 1.3202362 0.143826 -1.096889 1.4865083 -0.193056 -0.499020 1.5365404 -2.083647 -3.074591 0.1757725 -0.186138 -1.949731 0.2874326 -0.480790 -1.771560 -0.9302347 0.227383 -0.278253 2.1020048 -0.002592 1.434192 -1.6249159 0.404911 -2.167599 -0.452900 In [7]: df.idxmax()Out[7]:A 0B 8C 7 In [8]: df.ix[df[‘A’].idxmax()]Out[8]:A 2.001289B 0.482561C 1.579985 ···]]></content>
      <categories>
        <category>数据分析</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
        <tag>lambda</tag>
        <tag>agg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-27 dataframe与序列相乘]]></title>
    <url>%2F2017%2F08%2F27%2F2017-8-27-Pandas-dataframe%E4%B8%8E%E5%BA%8F%E5%88%97%E7%9B%B8%E4%B9%98%2F</url>
    <content type="text"><![CDATA[情景描述： 继续完成项目中的评分卡部分，拿到分好箱的数据后，如何进行加权得到最后的分数就是我们接下来要考虑的问题了。 demo1:1result = dataframe.mul(series, axis=0) demo2:12345678910111213141516def tile_df(df, n, m): dfn = df.T for _ in range(1, m): dfn = dfn.append(df.T, ignore_index=True) dfm = dfn.T for _ in range(1, n): dfm = dfm.append(dfn.T, ignore_index=True) return dfm df = pandas.DataFrame([[1,2],[3,4]])tile_df(df, 2, 3)# 0 1 2 3 4 5# 0 1 2 1 2 1 2# 1 3 4 3 4 3 4# 2 1 2 1 2 1 2# 3 3 4 3 4 3 4 demo3:12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; df = pd.DataFrame(np.random.randint(1, 10, (5, 3)))&gt;&gt;&gt; df 0 1 20 7 7 51 1 8 62 4 8 43 2 9 54 3 8 7&gt;&gt;&gt; df.prod(axis=1)0 2451 482 1283 904 168dtype: int64&gt;&gt;&gt; df = pd.DataFrame(np.random.randint(1, 10, (5, 3)))&gt;&gt;&gt; df 0 1 20 9 3 31 8 5 42 3 6 73 9 8 54 7 1 2&gt;&gt;&gt; df.apply(np.prod, axis=1)0 811 1602 1263 3604 14dtype: int64 demo4:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120In[197]: import pandas as pd; import numpy as np In [198]: df = pd.DataFrame(np.arange(40.).reshape((8, 5)), columns=list('abcde'));In [199]: dfOut[199]: a b c d e0 0.0 1.0 2.0 3.0 4.01 5.0 6.0 7.0 8.0 9.02 10.0 11.0 12.0 13.0 14.03 15.0 16.0 17.0 18.0 19.04 20.0 21.0 22.0 23.0 24.05 25.0 26.0 27.0 28.0 29.06 30.0 31.0 32.0 33.0 34.07 35.0 36.0 37.0 38.0 39.0In [200]: ser = pd.Series(np.arange(8) * 10);In [201]: serOut[201]:0 01 102 203 304 405 506 607 70dtype: int64In [202]: func = lambda x: np.asarray(x) * np.asarray(ser)In [203]: df.apply(func)Out[203]: a b c d e0 0.0 0.0 0.0 0.0 0.01 50.0 60.0 70.0 80.0 90.02 200.0 220.0 240.0 260.0 280.03 450.0 480.0 510.0 540.0 570.04 800.0 840.0 880.0 920.0 960.05 1250.0 1300.0 1350.0 1400.0 1450.06 1800.0 1860.0 1920.0 1980.0 2040.07 2450.0 2520.0 2590.0 2660.0 2730.0In [204]: df.apply(func).aOut[204]:0 0.01 50.02 200.03 450.04 800.05 1250.06 1800.07 2450.0Name: a, dtype: float64# 行相乘In[205]: ser2 = pd.Series(np.arange(5) *5); In [206]: ser2Out[206]: 0 0 1 5 2 10 3 15 4 20In[207]: func2 = lambda x: np.asarray(x) * np.asarray(ser2)In[8]: df.apply(func2, axis=1)Out[208]: a b c d e 0 0 5 20 45 80 1 0 30 70 120 180 2 0 55 120 195 280 3 0 80 170 270 380 4 0 105 220 345 480 5 0 130 270 420 580 6 0 155 320 495 680 7 0 180 370 570 780 # 进阶版In[209]: df.apply(lambda x: np.asarray(x) * np.asarray(ser))Out[209]: a b c d e 0 0 0 0 0 0 1 50 60 70 80 90 2 200 220 240 260 280 3 450 480 510 540 570 4 800 840 880 920 960 5 1250 1300 1350 1400 1450 6 1800 1860 1920 1980 2040 7 2450 2520 2590 2660 2730 In [210]: df.apply(lambda x: np.asarray(x) * np.asarray(ser)).aOut[210]:0 0.01 50.02 200.03 450.04 800.05 1250.06 1800.07 2450.0Name: a, dtype: float64In[211]: df.apply(lambda x: np.asarray(x) * np.asarray(ser2), axis=1)Out[211]: a b c d e 0 0 5 20 45 80 1 0 30 70 120 180 2 0 55 120 195 280 3 0 80 170 270 380 4 0 105 220 345 480 5 0 130 270 420 580 6 0 155 320 495 680 7 0 180 370 570 780 总结： 这样，我们总分也就拿到了，最后只需将每个项目的总分求和即可]]></content>
      <categories>
        <category>数据分析</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
        <tag>DataFrame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-27 python 协程加速]]></title>
    <url>%2F2017%2F08%2F27%2F2017-8-27-python-%E5%8D%8F%E7%A8%8B%E5%8A%A0%E9%80%9F%2F</url>
    <content type="text"><![CDATA[情景描述： 上周，由于产品嫌报告生成太慢，经过使用profile/gprof2dot研究后，发现主要时间耗费在接口网络请求上，于是我决定在项目中大量处理I/O网络请求的地方使用gevent,以缓解报告生成压力。 实现代码：123456789101112131415161718192021222324252627282930313233343536373839import geventfrom gevent import monkey, poolmonkey.patch_socket()p = pool.Pool(300)def requests_parse(self, tel_tuple): """ 主要处理requests请求 """ print('Size of pool', len(p)) …… ……def generator_label(self, tel_data): """ 使用gevent实现协程处理I/O网络请求 """ jobs = [p.spawn(self.requests_parse, tel) for tel in tel_data] gevent.joinall(jobs) tlist = [x.value for x in jobs] if None in tlist: message_list = [x.exception for x in jobs] self.logger.error(tlist) self.logger.error(message_list) raise Exception(message_list) return tlist def update_data_step(self, tel): """ 主要将请求回来处理好的数据写入数据库（mongo） """ res = self.db.update() …… ……tel_data = [……] # 一大堆待请求参数listtlist = self.generator_label(set(tel_data))map(lambda x: self.update_data_step(x[0])(x[1],x[2],x[3],x[4],x[5],x[6]), tlist) 问题： 上线后发现，代码运行一段时间后，请求一上来，任务数直线上升，一直增加：但是，pool的数量是正常的：之后log里报错信息： 1234567891011121314151617 File "run.py", line 42, in update_data File "report/generate/calls_sa_by_tel.py", line 396, in run File "report/generate/calls_sa_by_tel.py", line 38, in base_call File "venv/lib/python2.7/site-packages/pymongo/cursor.py", line 729, in count File "venv/lib/python2.7/site-packages/pymongo/collection.py", line 1344, in _count File "/usr/lib64/python2.7/contextlib.py", line 17, in __enter__ File "venv/lib/python2.7/site-packages/pymongo/mongo_client.py", line 904, in _socket_for_reads File "/usr/lib64/python2.7/contextlib.py", line 17, in __enter__ File "venv/lib/python2.7/site-packages/pymongo/mongo_client.py", line 870, in _get_socket File "/usr/lib64/python2.7/contextlib.py", line 17, in __enter__ File "venv/lib/python2.7/site-packages/pymongo/server.py", line 168, in get_socket File "/usr/lib64/python2.7/contextlib.py", line 17, in __enter__ File "venv/lib/python2.7/site-packages/pymongo/pool.py", line 844, in get_socket File "venv/lib/python2.7/site-packages/pymongo/pool.py", line 881, in _get_socket_no_auth File "venv/lib/python2.7/site-packages/pymongo/pool.py", line 817, in connect File "venv/lib/python2.7/site-packages/pymongo/pool.py", line 263, in _raise_connection_failureAutoReconnect: xxx.xxx.xxx.117:27017: [Errno 24] Too many open files 解决办法： 经过分析，解决办法：monkey.patch_socket()换为monkey.patch_all()，或者，在使用完gevent后使用reload(socket)将socket初始化。原因：应该是mongo写数据是阻塞的，请求快于写操作，导致写操作堆积越来越多，最终导致程序抛出Too many open files错误。最终代码，如下： 123456789101112131415161718192021222324import geventfrom gevent import monkey, poolmonkey.patch_all()def generator_label(self, tel_data): p = pool.Pool(10) jobs = [p.spawn(self.requests_parse, tel) for tel in tel_data] gevent.joinall(jobs) # print [x.value for x in jobs] tlist = [x.value for x in jobs] if None in tlist: message_list = [x.exception for x in jobs] self.logger.error(tlist) self.logger.error(message_list) raise Exception(message_list) return tlist # 或者使用p = pool.Pool(10)jobs = [p.spawn(self.requests_parse, tel) for tel in tel_data]gevent.joinall(jobs)import socketreload(socket) 另一个用例： 给传递两个参数，直接后面跟着就行，逗号分开；返回如是多个情况的，value是一个以tuple为元素的list。1234567891011p = pool.Pool(10)jobs = []# date ('2017-07-01', '2017-07-14')jobs = [p.spawn(self.crawl_a_call_log, date[0], date[1]) for date in dates]gevent.joinall(jobs)data_list = [x.value for x in jobs]print data_listif None in data_list: message_list = [x.exception for x in jobs] self.log('crawler', data_list, message_list) raise Exception(message_list) 总结 协程(gevent)是把双刃剑，monkey.patch 是一个邪恶的东西；提升效果不要太好，耗时足足降了60%，而且，请求越多，效果越明显。]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>gevent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-27 Pandas 分箱操作（cut）]]></title>
    <url>%2F2017%2F08%2F27%2F2017-8-27-Pandas-%E5%88%86%E7%AE%B1%E6%93%8D%E4%BD%9C%EF%BC%88cut%EF%BC%89%2F</url>
    <content type="text"><![CDATA[情景描述： 最新，项目中涉及到评分卡操作，评分项目有大概几十项，每项基本都是按频次区间给一个分数，最后，累计所有项目的分数得出最后所需要的分数。 demo1：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import pandas as pdimport numpy as npdf = pandas.DataFrame(&#123;"a": np.random.random(100), "b": np.random.random(100), "id": np.arange(100)&#125;)# Bin the data frame by "a" with 10 bins...bins = np.linspace(df.a.min(), df.a.max(), 10)# array([ 0.00282977, 0.11097259, 0.2191154 , 0.32725822, 0.43540104, 0.54354385, 0.65168667, 0.75982948, 0.8679723 , 0.97611511])# bins = np.linspace(0, 1, 11) # 优化版# array([ 0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])groups = df.groupby(np.digitize(df.a, bins))# Get the mean of each bin:print groups.mean() # Also could do "groups.aggregate(np.mean)"&gt;&gt;&gt;output: a b id1 0.044003 0.525964 56.3076922 0.167568 0.506078 55.4545453 0.268109 0.510612 44.6363644 0.375014 0.544154 69.8333335 0.481702 0.590031 48.5000006 0.599587 0.488921 38.0769237 0.696548 0.643555 50.6428578 0.830064 0.620650 50.5714299 0.928396 0.545460 44.16666710 0.976115 0.693051 28.000000# Similarly, the median:print groups.median()&gt;&gt;&gt;output: a b id1 0.028901 0.536857 61.02 0.167054 0.557716 49.03 0.267337 0.534911 43.04 0.374787 0.487063 73.05 0.480395 0.737007 49.56 0.603701 0.676479 42.07 0.695939 0.689144 57.58 0.836665 0.690757 41.09 0.924245 0.646487 47.010 0.976115 0.693051 28.0# Apply some arbitrary function to aggregate binned dataprint groups.aggregate(lambda x: np.mean(x[x &gt; 0.5]))&gt;&gt;&gt;output: a b id1 NaN 0.671236 56.3076922 NaN 0.704379 55.4545453 NaN 0.768609 44.6363644 NaN 0.804354 69.8333335 0.514166 0.796151 48.5000006 0.599587 0.755381 41.2500007 0.696548 0.779524 50.6428578 0.830064 0.766095 50.5714299 0.928396 0.902529 44.16666710 0.976115 0.693051 28.000000 demo2 :123456789101112131415161718192021222324import numpy as npimport pandasdf = pandas.DataFrame(&#123;"a": np.random.random(100), "b": np.random.random(100) + 10&#125;)# Bin the data frame by "a" with 10 bins...bins = np.linspace(df.a.min(), df.a.max(), 10)groups = df.groupby(pandas.cut(df.a, bins))# Get the mean of b, binned by the values in aprint groups.mean().b&gt;&gt;&gt;output:a(0.000351, 0.11] 10.596542(0.11, 0.22] 10.690010(0.22, 0.33] 10.250080(0.33, 0.44] 10.546134(0.44, 0.549] 10.471454(0.549, 0.659] 10.455624(0.659, 0.769] 10.501616(0.769, 0.879] 10.588354(0.879, 0.989] 10.461848Name: b, dtype: float64 demo3:12345678910111213141516171819202122232425In [144]: df = DataFrame(&#123;"a": np.random.random(100), "b": np.random.random(100), "id": np.arange(100)&#125;)In [145]: bins = [0, .25, .5, .75, 1]In [146]: a_bins = df.a.groupby(cut(df.a,bins))In [147]: b_bins = df.b.groupby(cut(df.b,bins))In [148]: a_bins.agg([mean,median])Out[148]: mean mediana(0, 0.25] 0.124173 0.114613(0.25, 0.5] 0.367703 0.358866(0.5, 0.75] 0.624251 0.626730(0.75, 1] 0.875395 0.869843In [149]: b_bins.agg([mean,median])Out[149]: mean medianb(0, 0.25] 0.147936 0.166900(0.25, 0.5] 0.394918 0.386729(0.5, 0.75] 0.636111 0.655247(0.75, 1] 0.851227 0.838805 demo4:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import pandas as pdimport numpy as npIn [168]: filter_values = [0, 5, 17, 33]In [169]: df = pd.DataFrame(np.random.random(100)*100, columns = ['filtercol'])In [170]: out = pd.cut(df.filtercol, bins = filter_values)In [171]: counts = pd.value_counts(out)Out[171]:(17, 33] 16(5, 17] 11(0, 5] 5# 排序counts = counts.reindex(out.cat.categories)counts = counts.sort_index()In [172]: counts = counts.reindex(out.cat.categories)In [173]: countsOut[173]:(0, 5] 5(5, 17] 11(17, 33] 16Name: filtercol, dtype: int64# 重置索引(reset index)out = counts.reset_index(drop=True) # counts 不变counts.reset_index(drop=True, inplace=True) # 直接改变countsIn [174]: out = counts.reset_index(drop=True)In [175]: outOut[175]:0 51 112 16Name: filtercol, dtype: int64In [176]: countsOut[176]:(0, 5] 5(5, 17] 11(17, 33] 16Name: filtercol, dtype: int64In [177]: counts.reset_index(drop=True, inplace=True)In [178]: countsOut[178]:0 51 112 16Name: filtercol, dtype: int64 总结： 第四个demo基本就可以完成当前目标了；后续需要操作的是封装一个合适的通用方法，将每个项目评分标准代入即可。]]></content>
      <categories>
        <category>数据分析</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
        <tag>cut</tag>
        <tag>评分卡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-23 mongo insert_many BulkWriteError]]></title>
    <url>%2F2017%2F08%2F23%2F2017-8-23-mongo-insert-many-BulkWriteError%2F</url>
    <content type="text"><![CDATA[问题： 在对mongo插入数据时，报写入问题，报错信息如下：12345678910Traceback (most recent call last): File &quot;/root/crs/call_history_crawler/worker/communicate.py&quot;, line 149, in insert_db_data if db[table].insert_many(data): File &quot;/root/crs/call_history_crawler/venv/lib/python2.7/site-packages/pymongo/collection.py&quot;, line 684, in insert_many blk.execute(self.write_concern.document) File &quot;/root/crs/call_history_crawler/venv/lib/python2.7/site-packages/pymongo/bulk.py&quot;, line 470, in execute return self.execute_command(sock_info, generator, write_concern) File &quot;/root/crs/call_history_crawler/venv/lib/python2.7/site-packages/pymongo/bulk.py&quot;, line 314, in execute_command raise BulkWriteError(full_result)BulkWriteError: batch op errors occurred 分析 问题出现在，对同一文本进行多次插入，官方说法：insert_many() with a list of references to a single document raises BulkWriteError123456789101112131415&gt;&gt;&gt; doc = &#123;&#125;&gt;&gt;&gt; collection.insert_many(doc for _ in range(10))Traceback (most recent call last):...pymongo.errors.BulkWriteError: batch op errors occurred&gt;&gt;&gt; doc&#123;&apos;_id&apos;: ObjectId(&apos;560f171cfba52279f0b0da0c&apos;)&#125;&gt;&gt;&gt; docs = [&#123;&#125;]&gt;&gt;&gt; collection.insert_many(docs * 10)Traceback (most recent call last):...pymongo.errors.BulkWriteError: batch op errors occurred&gt;&gt;&gt; docs[&#123;&apos;_id&apos;: ObjectId(&apos;560f1933fba52279f0b0da0e&apos;)&#125;]]]></content>
      <categories>
        <category>Bug</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Bug</tag>
        <tag>mongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-14 JSON文件 读写 格式化]]></title>
    <url>%2F2017%2F08%2F14%2F2017-8-14-JSON%E6%96%87%E4%BB%B6-%E8%AF%BB%E5%86%99-%E6%A0%BC%E5%BC%8F%E5%8C%96%2F</url>
    <content type="text"><![CDATA[写文件，格式化 indent: 缩进（一般填4，缩进4格）；sort_keys: 是否排序（默认False–不排序）1234567def write_info(file_name, file_info): with open('&#123;&#125;.json'.format(file_name), 'w') as fp: json.dump(file_info, fp, indent=4, sort_keys=True)write_info('report', dict(report_data))import json 读文件，格式化12345678910111213141516171819202122232425def pp_json(json_thing, sort=True, indents=4): if type(json_thing) is str: print(json.dumps(json.loads(json_thing), sort_keys=sort, indent=indents)) else: print(json.dumps(json_thing, sort_keys=sort, indent=indents)) return Nonepp_json(your_json_string_or_dict)&gt;&gt;&gt; import json&gt;&gt;&gt;&gt;&gt;&gt; your_json = '["foo", &#123;"bar":["baz", null, 1.0, 2]&#125;]'&gt;&gt;&gt; parsed = json.loads(your_json)&gt;&gt;&gt; print json.dumps(parsed, indent=4, sort_keys=True)[ "foo", &#123; "bar": [ "baz", null, 1.0, 2 ] &#125;]]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-13 三元表达式（条件表达式）]]></title>
    <url>%2F2017%2F08%2F13%2F2017-8-13-%E4%B8%89%E5%85%83%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%88%E6%9D%A1%E4%BB%B6%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[条件表达式： 使用一行代码快速判断，替换复杂的多行if语句，使得代码简单可维护。 12345# 如果条件为真，返回真，否则返回假condition_is_true if condition else condition_is_falseis_fat = Truestate = "fat" if is_fat else "not fat" 元组条件表达式：1234567# (返回假，返回真)[真或假](if_test_is_false, if_test_is_true)[test]fat = truefitness = ("skinny", "fat")[fat]print('All is ', fitness)# 输出： All is fat 注意： 原理：python中，True == 1，False == 0，相当于元组中使用0和1来选取数据； 这种写法不被推荐，原因：不Pythonic；容易把数据与true/false弄混；元祖中两个条件都执行，而if-else的条件表达式不会； 123456condition = Truepython(2 if condition else 1/0)# 输出：2print(1/0, 2)[condition]# 输出：ZeroDivisionError异常 解释： 元组先建数据，然后用True(1)/False(0)来索引数据； if-else条件表达式遵循普通的if-else逻辑树； 如果逻辑中有异常条件或重计算型（计算较久）的情况下，避免使用元组条件表达式。]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>条件表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-10 调试 Pdb（Python debugger）]]></title>
    <url>%2F2017%2F08%2F10%2F2017-8-10-%E8%B0%83%E8%AF%95-Pdb%EF%BC%88Python-debugger%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Pdb（Python debugger）：命令行运行：1python -m pdb my_script.py 脚本内部运行：12import pdbpdb.set_trace() 常用命令：123456c ：继续执行；w：显示上下文；a：打印当前函数参数列表；s：单步进入，进入函数内部（step）；n：单步跳过，不进入函数（next）；q：退出Pdb]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Debugger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-10 string 去掉标点符号]]></title>
    <url>%2F2017%2F08%2F10%2F2017-8-10-string-%E5%8E%BB%E6%8E%89%E6%A0%87%E7%82%B9%E7%AC%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[Python 字符串去掉标点符号最佳实践方法一： str.isalnum：S.isalnum() -&gt; boolReturn True if all characters in S are alphanumeric and there is at least one character in S, False otherwise. 123&gt;&gt;&gt; string = "Special $#! characters spaces 888323"&gt;&gt;&gt; ''.join(e for e in string if e.isalnum())'Specialcharactersspaces888323' 特点： 只能识别字母和数字，杀伤力大，会把中文、空格之类的也干掉 方法二： string.punctuation 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import re, strings ="string. With. Punctuation?" # Sample string # 写法一：out = s.translate(string.maketrans("",""), string.punctuation)# 写法二：out = s.translate(None, string.punctuation)# 写法三：exclude = set(string.punctuation)out = ''.join(ch for ch in s if ch not in exclude)# 写法四：&gt;&gt;&gt; for c in string.punctuation: s = s.replace(c,"")&gt;&gt;&gt; s'string With Punctuation'# 写法五：out = re.sub('[%s]' % re.escape(string.punctuation), '', s)## re.escape:对字符串中所有可能被解释为正则运算符的字符进行转义# 写法六：# string.punctuation 只包括 ascii 格式； 想要一个包含更广（但是更慢）的方法是使用： unicodedata module :from unicodedata import categorys = u'String — with - «Punctuation »...'out = re.sub('[%s]' % re.escape(string.punctuation), '', s)print 'Stripped', out# 输出：u'Stripped String \u2014 with \xabPunctuation \xbb'out = ''.join(ch for ch in s if category(ch)[0] != 'P')print 'Stripped', out# 输出：u'Stripped String with Punctuation '# For Python 3 str or Python 2 unicode values, str.translate() only takes a dictionary; codepoints (integers) are looked up in that mapping and anything mapped to None is removed.# To remove (some?) punctuation then, use:import stringremove_punct_map = dict.fromkeys(map(ord, string.punctuation))s.translate(remove_punct_map)# Your method doesn't work in Python 3, as the translate method doesn't accept the second argument any more. import unicodedataimport systbl = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P'))def remove_punctuation(text): return text.translate(tbl) 方法三： re 123import res ="string. With. Punctuation?"s = re.sub(r'[^\w\s]','',s) 测时：1234567891011121314151617181920212223242526272829303132import re, string, timeits ="string. With. Punctuation"exclude = set(string.punctuation)table = string.maketrans("","")regex = re.compile('[%s]' % re.escape(string.punctuation))def test_set(s): return ''.join(ch for ch in s if ch not in exclude)def test_re(s): return regex.sub('', s)def test_trans(s): return s.translate(table, string.punctuation)def test_repl(s): for c in string.punctuation: s=s.replace(c,"") return sprint"sets :",timeit.Timer('f(s)', 'from __main__ import s,test_set as f').timeit(1000000)print"regex :",timeit.Timer('f(s)', 'from __main__ import s,test_re as f').timeit(1000000)print"translate :",timeit.Timer('f(s)', 'from __main__ import s,test_trans as f').timeit(1000000)print"replace :",timeit.Timer('f(s)', 'from __main__ import s,test_repl as f').timeit(1000000)out_put:# sets : 19.8566138744# regex : 6.86155414581# translate : 2.12455511093# replace : 28.4436721802]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-9 Map、Filter、Reduce]]></title>
    <url>%2F2017%2F08%2F09%2F2017-8-9-Map%E3%80%81Filter%E3%80%81Reduce%2F</url>
    <content type="text"><![CDATA[Map 将一个函数映射到一个输入列表的所有元素上。 12345items = [1, 2, 3, 4, 5]squared = list(map(lambda x: x**2, items))# output:[1, 4, 9, 16, 25] map作用于一列表的函数：1234567891011121314151617def multiply(x): return (x*x)def add(x): return (x+x)funcs = [multiply, add]for i in xrange(5): value = map(lambda x: x(i), funcs) print(list(value))# Output:# [0, 0]# [1, 2]# [4, 4]# [9, 6]# [16, 8] 注：上面print加list转换，是为了python2/3的兼容，在python2中map直接返回列表，但在python3中返回迭代器。 Filter： 过滤列表元素，返回符合要求的元素所组成的列表；filter类似for循环，但更快。123456number_list = range(-5, 5)less_than_zero = filter(lambda x: x &lt; 0, number_list)print(list(less_than_zero)) # Output: [-5, -4, -3, -2, -1] Reduce： 对列表进行计算并返回结果。1234567891011# 计算列表乘积：from functools import reduceproduct = reduce( (lambda x, y: x * y), [1, 2, 3, 4] )# Output: 24# 计算静默期：count_times：func，计算静默时间blank_ret：listreduce(count_times, sorted(blank_ret))]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Map</tag>
        <tag>Filter</tag>
        <tag>Reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-8 profile cProfile 效率分析]]></title>
    <url>%2F2017%2F08%2F08%2F2017-8-8-profile-cProfile-%E6%95%88%E7%8E%87%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[test.py：123456789import osimport sysdef process(filename): print filenamefor (dirpath, dirnames, filenames) in os.walk(sys.argv[1]): for filename in filenames: process(filename) cProfile用法：12345678910111213141516171819202122232425# 生成.pstats分析文档python -m cProfile -o profile.pstats test.py /usr# 排序python -m cProfile -s tottime myscript.py# 查看pstats文档python -m pstats profile.pstats# ?: 查看可用指令；sort cumtime:排序；stats:查看pstats文档-s 选项：'calls' (call count)'cumulative' (cumulative time)'cumtime' (cumulative time)'file' (file name)'filename' (file name)'module' (file name)'ncalls' (call count)'pcalls' (primitive call count)'line' (line number)'name' (function name)'nfl' (name/file/line)'stdname' (standard name)'time' (internal time)'tottime' (internal time) gprof2dot用法:12345678# 安装 gprof2dotpip install gprof2dot# 通过.pstats文档生成相应的dot文档python -m gprof2dot -f pstats profile.pstats# 安装graphviz（centOS系统）sudo yum install graphviz# 输出png文档python -m gprof2dot -f pstats profile.pstats | dot -T png -o profile.png]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>cProfile</tag>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-7 pandas 获取不符合条件的dataframe]]></title>
    <url>%2F2017%2F08%2F07%2F2017-8-7-pandas-%E8%8E%B7%E5%8F%96%E4%B8%8D%E7%AC%A6%E5%90%88%E6%9D%A1%E4%BB%B6%E7%9A%84dataframe%2F</url>
    <content type="text"><![CDATA[search for “does-not-contain” on a dataframe in pandas 问题来源：做项目时，想拿到不符合条件的所有数据，比如：通话类型有好多种（主叫、被叫、呼转……），现在想分析所有非主叫数据，那么问题就来了。 方法一：df[~df.col.str.contains(word)]12345678910111213141516171819&gt;&gt;&gt; df = pd.DataFrame(&#123;"A": ["Hello", "this", "World", "apple"]&#125;)&gt;&gt;&gt; df.A.str.contains("Hello|World")0 True1 False2 True3 FalseName: A, dtype: bool&gt;&gt;&gt; ~df.A.str.contains("Hello|World")0 False1 True2 False3 TrueName: A, dtype: bool&gt;&gt;&gt; df[~df.A.str.contains("Hello|World")] A1 this3 apple[2 rows x 1 columns] 注意： 似乎 df[~(df.A.str.contains(&quot;Hello&quot;) | (df.A.str.contains(&quot;World&quot;)))]比上面使用正则，速度会快点 获取“非”数据的条数：(~df.col3.str.contains(&#39;u|z&#39;)).sum() 方法二：123456789df[df["col"].str.contains('this'|'that')==False]&gt;&gt;&gt; df = pd.DataFrame(&#123;"A": ["Hello", "this", "World", "apple"]&#125;)&gt;&gt;&gt; df[df['A'].str.contains("Hello|World")==False] A1 this3 apple# 多个条件情况下：# df[df["col1"].str.contains('this|that')==False and df["col2"].str.contains('foo|bar')==True] 方法三：1234567891011&gt;&gt;&gt; df = pd.DataFrame(&#123;"A": ["Hello", "this", "World", "apple"]&#125;)&gt;&gt;&gt; df['A'].str.contains(r'^(?:(?!Hello|World).)*$')0 False1 True2 False3 TrueName: A, dtype: bool&gt;&gt;&gt; df[df['A'].str.contains(r'^(?:(?!Hello|World).)*$')] A1 this3 apple]]></content>
      <categories>
        <category>数据分析</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
        <tag>Contains</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-7 python args and kwargs]]></title>
    <url>%2F2017%2F08%2F07%2F2017-8-7-python-args-and-kwargs%2F</url>
    <content type="text"><![CDATA[*args： 传递一个非键值对的可变数量的参数列表给一个函数。123456789101112def test_var_args(f_arg, *argv): print("first normal arg:", f_arg) for arg in argv: print("another arg through *argv:", arg)test_var_args('yasoob', 'python', 'eggs', 'test')# output：# first normal arg: yasoob# another arg through *argv: python# another arg through *argv: eggs# another arg through *argv: test **kwargs： 传递不定长度的键值对（字典）, 作为参数传递给一个函数（即传递带名字的参数）。123456def greet_me(**kwargs): for key, value in kwargs.items(): print("&#123;0&#125; == &#123;1&#125;".format(key, value))&gt;&gt;&gt; greet_me(name="yasoob")name == yasoob 注意： 不是必须写成*args和**kwargs，只有变量前面的 *(星号)才是必须的；可以写成*var 和**vars，写成*args 和**kwargs只是一个通俗的命名约定；*args： 顺序不能变动；**kwargs：可以根据键指定顺序。123456789101112131415161718def test_args_kwargs(arg1, arg2, arg3): print("arg1:", arg1) print("arg2:", arg2) print("arg3:", arg3) # 首先使用 *args&gt;&gt;&gt; args = ("two", 3, 5)&gt;&gt;&gt; test_args_kwargs(*args)arg1: twoarg2: 3arg3: 5# 现在使用 **kwargs:&gt;&gt;&gt; kwargs = &#123;"arg3": 3, "arg2": "two", "arg1": 5&#125;&gt;&gt;&gt; test_args_kwargs(**kwargs)arg1: 5arg2: twoarg3: 3]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>args</tag>
        <tag>kwargs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-6 python string]]></title>
    <url>%2F2017%2F08%2F06%2F2017-8-6-python-string%2F</url>
    <content type="text"><![CDATA[The most pythonic way to pad zeroes to stringStrings:12345678910111213141516171819&gt;&gt;&gt; n = '4'&gt;&gt;&gt; n.zfill(3)&gt;&gt;&gt; '004'&gt;&gt;&gt; '&#123;:0&gt;3&#125;'.format(n)&gt;&gt;&gt; '004'&gt;&gt;&gt; '&#123;1&#125;&#123;1&#125;&#123;0&#125;'.format(n, '0')&gt;&gt;&gt; '004'&gt;&gt;&gt; '&#123;:0&lt;3&#125;'.format(n)&gt;&gt;&gt; '400'&gt;&gt;&gt; '&#123;:-^11&#125;'.format(n)&gt;&gt;&gt; '-----4-----'&gt;&gt;&gt; n.rjust(3, '0')&gt;&gt;&gt; '004'&gt;&gt;&gt; n.ljust(3, '0')&gt;&gt;&gt; '400'&gt;&gt;&gt; '4'.center(11,"-")&gt;&gt;&gt; '-----4-----' rjust/zfill 区别:1234567891011121314zfill:&gt;&gt;&gt; '--txt'.zfill(10)&gt;&gt;&gt; '-00000-txt'&gt;&gt;&gt; '++txt'.zfill(10)&gt;&gt;&gt; '+00000+txt'&gt;&gt;&gt; '..txt'.zfill(10)&gt;&gt;&gt; '00000..txt'rjust:&gt;&gt;&gt; '--txt'.rjust(10, '0')&gt;&gt;&gt; '00000--txt'&gt;&gt;&gt; '++txt'.rjust(10, '0')&gt;&gt;&gt; '00000++txt'&gt;&gt;&gt; '..txt'.rjust(10, '0')&gt;&gt;&gt; '00000..txt' numbers:123456789101112131415&gt;&gt;&gt; n = 4&gt;&gt;&gt; print '%03d' % n004&gt;&gt;&gt; print format(n, '03') # python &gt;= 2.6004&gt;&gt;&gt; print '&#123;0:03d&#125;'.format(n) # python &gt;= 2.6004&gt;&gt;&gt; print '&#123;foo:03d&#125;'.format(foo=n) # python &gt;= 2.6004&gt;&gt;&gt; print('&#123;:03d&#125;'.format(n)) # python &gt;= 2.7 + python3004&gt;&gt;&gt; print('&#123;0:03d&#125;'.format(n)) # python 3004&gt;&gt;&gt; print(f'&#123;n:03&#125;') # python &gt;= 3.6004 % formatting 已被 string.format 替代 保留小数位：123456format(value, '.6f')&gt;&gt;&gt; format(2.0, '.6f')'2.000000'&gt;&gt;&gt; '&#123;:.6f&#125;'.format(2.0)'2.000000']]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-8-1 python rrule bug]]></title>
    <url>%2F2017%2F08%2F01%2F2017-8-1-python-rrule-bug%2F</url>
    <content type="text"><![CDATA[http://dateutil.readthedocs.io/en/stable/_modules/dateutil/rrule.html 月份日期超限 BUG Per RFC section 3.3.10, recurrence instances falling on invalid dates and times are ignored rather than coerced:Recurrence rules may generate recurrence instances with an invalid date (e.g., February 30) or nonexistent local time (e.g., 1:30 AM on a day where the local time is moved forward by an hour at 1:00 AM).Such recurrence instances MUST be ignored and MUST NOT be counted as part of the recurrence set. This can lead to possibly surprising behavior when, for example, the start date occurs at the end of the month:12345678&gt;&gt;&gt; from dateutil.rrule import rrule, MONTHLY&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; start_date = datetime(2014, 12, 31)&gt;&gt;&gt; list(rrule(freq=MONTHLY, count=4, dtstart=start_date))[datetime.datetime(2014, 12, 31, 0, 0),datetime.datetime(2015, 1, 31, 0, 0),datetime.datetime(2015, 3, 31, 0, 0),datetime.datetime(2015, 5, 31, 0, 0)]]]></content>
      <categories>
        <category>Bug</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Bug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-7-31 python set 交集、并集、差集]]></title>
    <url>%2F2017%2F07%2F31%2F2017-7-31-python-%E4%BA%A4%E9%9B%86%E3%80%81%E5%B9%B6%E9%9B%86%E3%80%81%E5%B7%AE%E9%9B%86%2F</url>
    <content type="text"><![CDATA[交集(intersection)1234567891011121314151617181920example：valid = set(['yellow', 'red', 'blue', 'green', 'black'])input_set = set(['red', 'brown']) print(input_set.intersection(valid))### 输出：set(['red'])# 方法一:&gt;&gt;&gt; a=[2,3,4,5]&gt;&gt;&gt; b=[2,5,8]&gt;&gt;&gt; tmp = [val for val in a if val in b]&gt;&gt;&gt; tmp[2, 5]# 方法二&gt;&gt;&gt; list(set(a).intersection(set(b)))[2, 5]# 方法三：&gt;&gt;&gt;list(set(a) &amp; set(b))[2, 5] 字符串交集1234567891011121314151617181920# 方法一：''.join(sorted(set(str1) &amp; set(str2), key = str1.index))# 方法二：def strIntersection(s1, s2): out = "" for c in s1: if c in s2 and not c in out: out += c return out# 方法三：&gt;&gt;&gt; a='asdfasdfasfd'&gt;&gt;&gt; b='qazwsxedc'&gt;&gt;&gt; set(a).intersection(b)set(['a', 's', 'd'])# 方法四：def hasIntersection(a, b): return not set(a).isdisjoint(b) 最大交集 How to find all intersections (also called the longest common substrings) of two strings and their positions in both strings?For example:if S1=”never” and S2=”forever” then resulted intersection must be [“ever”] and its positions are [(1,3)].If S1=”address” and S2=”oddness” then resulted intersections are [“dd”,”ess”] and their positions are [(1,1),(4,4)]. 123456789101112131415161718192021222324252627282930# 方法一：In [31]: import difflibIn [32]: difflib.SequenceMatcher(None, "never", "forever").get_matching_blocks()Out[32]: [Match(a=1, b=3, size=4), Match(a=5, b=7, size=0)]In [33]: difflib.SequenceMatcher(None, "address", "oddness").get_matching_blocks()Out[33]: [Match(a=1, b=1, size=2), Match(a=4, b=4, size=3), Match(a=7, b=7, size=0)]# 方法二：import itertoolsdef longest_common_substring(s1, s2): set1 = set(s1[begin:end] for (begin, end) in itertools.combinations(range(len(s1)+1), 2)) set2 = set(s2[begin:end] for (begin, end) in itertools.combinations(range(len(s2)+1), 2)) common = set1.intersection(set2) maximal = [com for com in common if sum((s.find(com) for s in common)) == -1 * (len(common)-1)] return [(s, s1.index(s), s2.index(s)) for s in maximal] &gt;&gt;&gt; longest_common_substring('address', 'oddness')[('dd', 1, 1), ('ess', 4, 4)]&gt;&gt;&gt; longest_common_substring('never', 'forever')[('ever', 1, 3)]&gt;&gt;&gt; longest_common_substring('call', 'wall')[('all', 1, 1)]&gt;&gt;&gt; longest_common_substring('abcd1234', '1234abcd')[('abcd', 0, 4), ('1234', 4, 0)] 并集(union)1234567# 方法一：&gt;&gt;&gt; list(set(a).union(set(b)))[2, 3, 4, 5, 8]# 方法二：&gt;&gt;&gt; list(set(b) | (set(a)))[2, 3, 4, 5, 8] 差集(difference) 差集：找出无效的数据，相当于用一个集合减去另一个集合的数据。12345678910111213# example：valid = set(['yellow', 'red', 'blue', 'green', 'black'])input_set = set(['red', 'brown'])print(input_set.difference(valid))### 输出: set(['brown'])# 方法一：&gt;&gt;&gt; list(set(b).difference(set(a))) # b中有而a中没有的[8]# 方法二：&gt;&gt;&gt; list(set(b) - (set(a)))[8] 集合操作汇总123456789101112131415161718192021222324252627&gt;&gt;&gt; x = set('abcde')&gt;&gt;&gt; y = set('bdxyz')&gt;&gt;&gt; xset(['a', 'c', 'b', 'e', 'd']) # 2.6 display format&gt;&gt;&gt; 'e' in x # Membership 成员True&gt;&gt;&gt; x – y # Difference 差集set(['a', 'c', 'e'])&gt;&gt;&gt; x | y # Union 并集set(['a', 'c', 'b', 'e', 'd', 'y', 'x', 'z'])&gt;&gt;&gt; x &amp; y # Intersection 交集set(['b', 'd'])&gt;&gt;&gt; x ^ y # Symmetric difference (XOR) 补集set(['a', 'c', 'e', 'y', 'x', 'z'])&gt;&gt;&gt; x &gt; y, x &lt; y # Superset, subset 父级，子级(False, False) 巨型集合处理（数量在百万，千万甚至更大） 方法一：set特点： 速度快； 内存消耗大，一个1万个元素的集合，其占用的内存远大于1万 * 每个元素的大小，因为整个set数据结构占用大量其他空间来存储索引之类的东西。 123并集：s.union(t) 或者 s | t交集：s.intersection(t) 或者 s &amp; t差集：s.difference(t) 或者 s - t 方法二：Numpy特点： 先把要操作的元素放在数组而不是set中，同样内容的数组占用的内存比set小的多；占用内存小于set的方式； 速度接近set方式。12345import numpy as np并集： np.union1d(s, t) # 返回排序的、去重的两个list的合集交集： np.intersect1d(s, t, assume_unique=True) # 返回排序的、去重的两个list的交集，尽可能保证传入的两个list是去重的，这可以加快运算速度。差集： np.setdiff1d(s, t, assume_unique=True) # 返回排序的，去重的差集，assume_unique参数同上。 方法三：cmd以上两种方法的缺点就是当集合足够大而内存又不够的时候，会MemoryError（在试验中2000万个长度为24的字符串在4G的内存中就报MemoryError了）；解决办法：使用linux 命令。特点： 内存消耗小，会使用临时文件来避免内存问题； 耗时长。1234561.文件排序，使用sort命令：sort --buffer-size=1G --output=/path/to/output /path/to/src_file # --buffer-size在Debian上可用，其他平台未知，不是标准参数.并集：sort -m /path/to/src1 /path/tosrc2 -u --output=/path/to/result # 注意src1, src2必须是已排序的文件，而且结果也是已排序的。交集：comm -12 file1 file2 &gt; output # 使用comm命令，注意传入的文件必须都是已排序的。差集：comm -3 file1 file2 &gt; output # 使用comm命令，注意传入的文件必须都是已排序的。 综上，三种方法依次对内存的依赖减小，耗时增加，可依据集合大小以及硬件环境来选择。]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-7-31 python 生成器（Generators）]]></title>
    <url>%2F2017%2F07%2F31%2F2017-7-31-python-%E7%94%9F%E6%88%90%E5%99%A8%EF%BC%88Generators%EF%BC%89%2F</url>
    <content type="text"><![CDATA[可迭代对象（iterable）： 能提供迭代器的任意对象；只要定义了一个迭代器的iter方法或定义了支持下标索引的getitem方法，那就是一个可迭代对象。 迭代器（iterators）： 任意对象，只要定义了next或者next方法，那就是一个迭代器 迭代（iteration）： 从某个地方（如列表）取出一个元素的过程；使用一个循环来遍历某个东西（如列表），这个过程就是迭代； 生成器（Generators）： 也是一种迭代器，但只能对其迭代一次 因为它们并没有把所有值存在内存中，而是运行时生成值； 可通过遍历使用它们，要么使用“for”循环，要么传递给任意可以进行迭代的函数和结构； 大多时候生成器是以函数实现的，但它们并不返回一个值，而是yield（生出）一个值。1234567891011121314151617def generator_function(): for i in range(10): yield ifor item in generator_function(): print(item)# Output: 0# 1# 2# 3# 4# 5# 6# 7# 8# 9 适用场景： 不想同一时间将所有计算出来的大量结果集分配到内存当中，特别是结果集里还包含循环；因为这样做会消耗大量资源许多Python 2里的标准库函数都会返回列表，而Python 3都修改成了返回生成器，因为生成器占用更少的资源。 **斐波那契数列的生成器： 12345678910111213141516171819# 传统模式def fibon(n): a = b = 1 result = [] for i in range(n): result.append(a) a, b = b, a + b return result# 生成器模式def fibon(n): a = b = 1 for i in range(n): yield a a, b = b, a + b# Now we can use it like this:for x in fibon(1000000): print(x) Python内置函数：next() 它允许我们获取一个序列的下一个元素特点： 在yield掉所有的值后，next()会触发一个StopIteration的异常。提示我们所有的值都已经被yield完了； 在使用for循环时没有这个异常，因为for循环会自动捕捉到这个异常并停止调用next()。123456789101112131415def generator_function(): for i in range(3): yield igen = generator_function()print(next(gen))# Output: 0print(next(gen))# Output: 1print(next(gen))# Output: 2print(next(gen))# Output: Traceback (most recent call last):# File "&lt;stdin&gt;", line 1, in &lt;module&gt;# StopIteration Python内置函数：iter() 将一个可迭代对象返回一个迭代器对象12345my_string = "Bingo"next(my_string)# Output: Traceback (most recent call last):# File "&lt;stdin&gt;", line 1, in &lt;module&gt;# TypeError: str object is not an iterator 这个异常说str对象是一个可迭代对象，而不是一个迭代器；不能直接对其进行迭代操作，所以，使用iter：12345678910111213141516my_string = "Bingo"my_iter = iter(my_string)next(my_iter)# Output: 'B'next(my_iter)# Output: 'i'next(my_iter)# Output: 'n'next(my_iter)# Output: 'g'next(my_iter)# Output: 'o'next(my_iter)# Output: Traceback (most recent call last):# File "&lt;stdin&gt;", line 12, in &lt;module&gt;# StopIteration]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>generators</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-24 建站日志（二）]]></title>
    <url>%2F2017%2F05%2F24%2F2017-5-24-%E5%BB%BA%E7%AB%99%E6%97%A5%E5%BF%97%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[到此，建站告一段落，功能差不多完善了 2017-05-24：Bootstrap Callout的巨坑BUG 在今天新增添加评论后，部署完成后发现，界面变成如下：完全乱码了，真是…经过一晚上排查，发现原因出在：Markdown开头我使用了Bootstrap Callout语句，中间写了其他代码，结尾又再次使用了Bootstrap Callout语句，如下图：把结尾的Bootstrap Callout语句去掉之后，一切又恢复了正常。 难道Bootstrap Callout语句一篇文章只能使用一次？？？ 为了验证，做了如下测试：果然如此，真是绝了…对了，连下面这种情况（Bootstrap Callout）也不能出现，出现了也算一次：1`&#123;% note info %&#125; ... &#123;% endnote %&#125;` #单引号小代码块 添加评论 这里我用的是Hypercomments，国外的一个第三方评论平台，好处之一就是可以支持匿名评论，不用登录就可以进行评论，取代即将入土的多说。 1.Next主题已经集成了Hypercomments，只需到Hypercomments注册一个账号，绑定网站入口，拿到widget_id即可。具体位置如下： 代码中找到widget_id:xxxxx：1widget:&quot;Stream&quot;, widget_id: xxxxx 2.修改主题配置文件，找到如下代码：12# Hypercomments#hypercomments_id: 3.取消注释，将拿到的widget_id填入，即可。预览： 使用七牛做图片图床 为了提高页面加载速度，方便图片管理，将博客所有图片均同步到七牛云，制成外链，加到博客中。 步骤很简单，注册一个七牛云账号，新建一个存储空间，将用到的图片传上去，拿到外链，写博客时，如下使用就可以了。1![](http://ohhmsby4v.bkt.clouddn.com/image/2017-05-24_%E5%BB.png) 2017-05-21：Markdown内置标签 文本居中的引用123456789&lt;!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --&gt;&lt;!-- 其中 class=&quot;blockquote-center&quot; 是必须的 --&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;blah blah blah&lt;/blockquote&gt;&lt;!-- 标签 方式，要求版本在0.4.5或以上 --&gt;&#123;% centerquote %&#125;blah blah blah&#123;% endcenterquote %&#125;&lt;!-- 标签别名 --&gt;&#123;% cq %&#125; blah blah blah &#123;% endcq %&#125; 预览：人的一切痛苦，本质上都是对自己的无能的愤怒。 突破容器宽度限制的图片123456789&lt;!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --&gt;&lt;!-- 其中 class=&quot;full-image&quot; 是必须的 --&gt;&lt;img src=&quot;/image-url&quot; class=&quot;full-image&quot; /&gt;&lt;!-- 标签 方式，要求版本在0.4.5或以上 --&gt;&#123;% fullimage /image-url, alt, title %&#125;&lt;!-- 别名 --&gt;&#123;% fi /image-url, alt, title %&#125; 预览： Bootstrap Callout12345678&#123;% note class_name %&#125; Content (md partial supported) &#123;% endnote %&#125;&#123;% note %&#125; Content (md partial supported of **none**) &#123;% endnote %&#125;&#123;% note default %&#125; Content (md partial supported of **default**) &#123;% endnote %&#125;&#123;% note primary %&#125; Content (md partial supported of **primary**) &#123;% endnote %&#125;&#123;% note success %&#125; Content (md partial supported of **success**) &#123;% endnote %&#125;&#123;% note info %&#125; Content (md partial supported of **info**) &#123;% endnote %&#125;&#123;% note warning %&#125; Content (md partial supported of **warning**) &#123;% endnote %&#125;&#123;% note danger %&#125; Content (md partial supported of **danger**) &#123;% endnote %&#125; * class_name可以为：default、primary、success、info、warning、danger，也可以为空。预览： 完]]></content>
      <categories>
        <category>Notes</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-23 一个逗号(,)引起的BUG]]></title>
    <url>%2F2017%2F05%2F23%2F2017-5-23-%E4%B8%80%E4%B8%AA%E9%80%97%E5%8F%B7-%E5%BC%95%E8%B5%B7%E7%9A%84BUG%2F</url>
    <content type="text"><![CDATA[昨天工作，突然发现之前好好的list，在赋值给新变量后居然类型变了，一个好好的list几分钟不见妥妥的叛变了，变成了tuple，由此，一场闹剧开始上演… 前情回要：话说有一个类对象内有一方法如下：123def call_frequency(self, data): ... return list 返回的是一个list，内部是一个个dict，结构如下：1[&#123;xx:xxx,xx:xxx&#125;,&#123;xx:xxx,&#125;,&#123;x:xxx&#125;,...] 闹剧上演： ok，开始今天任务，开始在另一方法中调用赋值：1data_list = self.call_frequency(data) 结果print data_list，返回值如下：1([&#123;xx:xxx,xx:xxx&#125;,&#123;xx:xxx,&#125;,&#123;x:xxx&#125;,...],) what a fxxk，瞬间，凌乱了，还以为发现新天地了，啊！原来，list赋值后会变成tuple，加个马甲，以前怎么没发现呢…还自以为是的在调用data_list时，如下：1call_tel_list = [v.get(&quot;call_tel&quot;,&quot;&quot;) for v in data_list[0]] 惊天逆转晚上，回家，比较得意，欸，又学到一招，不错哟，积蓄，努力。 8小时后，天亮了：1data_list = self.call_frequency(data), 咦，这里怎么有个逗号？ 瞬间，懵逼… 四下瞅瞅， 然后，按下←，整个世界清静了，再悄悄把昨天的杰作恢复本来面目， 嗯，今天，天气真好。 真的！ 完]]></content>
      <categories>
        <category>Bug</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>list</tag>
        <tag>tuple</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-17 Markdown 常用语法]]></title>
    <url>%2F2017%2F05%2F17%2F2017-5-17-Markdown-%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[标题(一)代码：123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 效果： 标题(二)代码：1234标题（#）==标题（##）-- 效果： 无序列表代码：1234- 文本1 * 二级文本- 文本2- 文本3 效果： 文本1 二级文本 文本2 文本3 有序列表代码：1231. 文本12. 文本23. 文本3 效果： 文本1 文本2 文本3 文字链接代码：12[显示文本](链接地址)[悟の迹](http://chihweihsu.com/) 效果： 悟の迹 自动链接代码：1&lt;http://chihweihsu.com/&gt; 效果： http://chihweihsu.com/ 参考式链接代码：1234567I get 10 times more traffic from [Google] [1] than from [Yahoo] [2] or [MSN] [3],but most traffic is [悟の迹] [4]. [1]: http://google.com/ &quot;Google&quot; [2]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [3]: http://search.msn.com/ &quot;MSN Search&quot; [4]: http://chihweihsu.com/ &quot;悟の迹&quot; 效果： I get 10 times more traffic from Google than from Yahoo or MSN, but most traffic is 悟の迹. 插入图片代码：12![alt text](图片链接 &quot;title&quot;)![悟](http://ohhmsby4v.bkt.clouddn.com/image/%E6%82%9F.jpg) 效果： 代码代码：1`code` 效果： code 代码块代码（去空格）：123` ` ` code` ` ` 效果：1code 引用代码：12345&gt; 引用文字&gt;&gt; &gt; 二级引用文字&gt;&gt; 引用文字 效果： 引用文字 二级引用文字 引用文字 斜体代码：1*斜体文字* 效果： 斜体文字 粗体代码：1**粗体文字** 效果： 粗体文字 粗斜体代码：1***粗斜体*** 效果： 粗斜体 删除线代码：1~~删除线~~ 效果： 删除线 注脚代码：12这是一个注脚[^footnote1]的样例[^1]: 我就是悟 效果： 这是一个注脚[^footnote1]的样例 表格(一)代码：12345| Tables | Are | Cool || ----- | :-----: | -----: || col 3 is | right-aligned | $1600 || col 2 is | center | $12 || zebra stipes | are neat | $1 | 效果： Tables Are Cool col 3 is right-aligned $1600 col 2 is center $12 zebra stipes are neat $1 表格(二)代码：12345dog | bird | cat----|------|-----foo | foo | foobar | bar | barbaz | baz | baz 效果： dog bird cat foo foo foo bar bar bar baz baz baz 转义代码：12345678910111213141516\*悟の迹\*支持以下符号转义：\ 反斜线` 反引号* 星号_ 底线&#123;&#125; 花括号[] 方括号() 括弧# 井字号+ 加号- 减号. 英文句点! 惊叹号&gt; 大于号 效果： *悟の迹* 最近访客]]></content>
      <categories>
        <category>Notes</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>速查</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-17 建站日志]]></title>
    <url>%2F2017%2F05%2F17%2F2017-5-17-%E5%BB%BA%E7%AB%99%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[未完待续… 2017-05-19：添加新 Page 1.用如下命令添加新page: 12345678hexo new page &quot;categories&quot;hexo new page &quot;tags&quot;hexo new page &quot;Python&quot;hexo new page &quot;Linux&quot;hexo new page &quot;Notes&quot;hexo new page &quot;Something&quot;hexo new page &quot;Links&quot;hexo new page &quot;About&quot; 2.打开主题配置文件`\themes\next_config.yml文件，在menu`中添加：1234567891011menu: home: / archives: /archives categories: /categories tags: /tags Python: /Python Linux: /Linux Notes: /Notes Something: /Something Links: /Links About: /About 3.打开\themes\next\languages\zh-Hans.yml，修改menu：1234567891011menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 python: Python linux: Linux notes: 笔记 something: 有料 links: 链接 about: 关于 *注意这里第一列必须全为小写。 *这是简体中文的配置文件，如果你的博客用的是其他语言，请打开对应的文件。 修改blog页面配色 添加自定义颜色打开\themes\next\source\css\ _variables\base.styl文件，修改：1234567891011121314151617181920212223// Colors// colors for use across theme.// --------------------------------------------------$whitesmoke = #f5f5f5$gainsboro = #eee$gray-lighter = #ddd$grey-light = #ccc$grey = #bbb$grey-dark = #999$grey-dim = #666$black-light = #555$black-dim = #333$black-deep = #222$red = #ff2a2a$blue-bright = #87daff$blue = #0684bd$blue-deep = #262a30$orange = #fc6423// 下面是我自定义的颜色$my-link-blue = #0593d3 //链接颜色$my-link-hover-blue = #0477ab //鼠标悬停后颜色$my-code-foreground = #dd0055 // 用``围出的代码块字体颜色$my-code-background = #eee // 用``围出的代码块背景颜色 修改超链接颜色还是base.styl文件，修改这几行：12345// Global link color.$link-color = $my-link-blue$link-hover-color = $my-link-hover-blue$link-decoration-color = $gray-lighter$link-decoration-hover-color = $my-link-hover-blue 预览： 修改小型代码块颜色依旧是base.styl文件，修改$code-background和$code-foreground的值：12345678// Code &amp; Code Blocks// 用``围出的代码块// --------------------------------------------------$code-font-family = $font-family-monospace$code-font-size = 15px$code-background = $my-code-background$code-foreground = $my-code-foreground$code-border-radius = 4px 预览： 修改blog页面字体大小 打开\themes\next\source\css\ _variables\base.styl文件，找到：12// Font size$font-size-base = 14px 改为：1$font-size-base = 16px 修改blog页面宽度 现在一般都用宽屏显示器，博客页面两侧留白太多，调整一下宽度。 1.打开\themes\next\source\css\_common\components\post\post-expand.styl，找到:1@media (max-width: 767px) 改为1@media (max-width: 1080px) 2.打开\themes\next\source\css\ _variables\base.styl文件，找到：123$main-desktop = 960px$main-desktop-large = 1200px$content-desktop = 700px 改为：123$main-desktop = 1080px$main-desktop-large = 1200px$content-desktop = 810px 修改博客部署的message 在\node_modules\hexo-deployer-git\lib\deployer.js文件末尾找到：1Site updated: &#123;&#123; now(&apos;YYYY-MM-DD HH:mm:ss&apos;) &#125;&#125; 改得个性化一点：1好家伙又改版了悟の迹: &#123;&#123; now(&apos;YYYY-MM-DD HH:mm:ss&apos;) &#125;&#125; Github项目主页添加README 问题原因：Github上博客的仓库主页没有README，如果把README.md放入source文件夹，hexo g生成时会被解析成html文件，而放到public文件夹中，生成时又会自动删除。 解决方法:在source目录下新建文件README.mdown，在里面写README即可。hexo g会把它复制到public文件夹，且不会被解析成html Github项目主页添加LICENSE 修改主题配置文件，找到：12345# Creative Commons 4.0 International License.# http://creativecommons.org/# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zerocreative_commons: by-nc-sa#creative_commons: 将其中第 4 行的注释放开，然后选择你想使用的 LICENSE 即可，可选项参照第 3 行。 SEO优化 为优化SEO，更改首页标题格式为「关键词-网站名称 - 网站描述」 打开\themes\next\layout\index.swig文件，找到这行代码：1&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; &#123;% endblock %&#125; 把它改成：123&#123;% block title %&#125; &#123;&#123; theme.keywords &#125;&#125; - &#123;&#123; config.title &#125;&#125; - &#123;&#123; theme.description &#125;&#125;&#123;% endblock %&#125; 添加“Fork me on Github” ribbon 1.点击Fork me on Github； 2.给blog主页选择一个绶带（ribbon），并复制相应代码； 3.找到正在使用的theme下的layout文件，将代码插入即可； 4.比如我选择了红色的ribbon，使用的themes为next，那么只要打开 blog\themes\next\layout\_layout.swig文件，复制下面这段代码，放在最后，标签之前即可。（注意将https://github.com/you改为你自己的github链接）1234&lt;a href=&quot;https://github.com/you&quot;&gt; &lt;img style=&quot;position: absolute; top: 0; right: 0; border: 0;&quot; src=&quot;https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67&quot; alt=&quot;Fork me on GitHub&quot; data-canonical-src=&quot;https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png&quot;&gt;&lt;/a&gt; 添加404公益页面 在blog/source下新建自己的404.html文件即可，强推腾讯公益404，代码可参考如下：123456789101112---layout: default---&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;404&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;http://chihweihsu.com/&quot; homePageName=&quot;回到悟の迹&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 文章阅读次数统计 1.注册LeanCloud帐号并验证邮箱； 2.创建应用，新建一个应用来专门进行博客的访问统计的数据操作； 3.创建完成之后我们点击新创建的应用的名字来进行该应用的参数配置； 4.新建一个Class用来专门保存我们博客的文章访问量等数据； 5.新建Class名字必须为Counter，设置默认的ACL权限，建议在此处选择无限制； 6.选择左侧的应用Key选项，拿到我们创建应用的AppID以及AppKey； 7.编辑 主题配置文件，如下:1234leancloud_visitors: enable: true app_id: joaeuuc4hsqudUUwx4gIvGF6-gzGzoHsz app_key: E9UJsJpw1omCHuS22PdSpKoh 8.ok，部署后可见。 2017-05-18：配置导航栏网站小图标 挑选一张图片，名字改为favicon.ico，放到..\blog\source下，配置主题配置文件如下：1favicon: /favicon.ico 集成百度分享模块 首先，编辑 站点配置文件，末尾添加字段:1baidushare: true #百度分享功能 其次，编辑主题配置文件，找到如下代码位置，去掉最后两行#注释，并选择展示方式，建议slide悬浮状态：123456# Baidu Share# Available value:# button | slide# Warning: Baidu Share does not support https.baidushare: type: slide #百度分享展示的方式button|slide *注意：百度分享不支持https方式，可以自己买个域名绑定，或者搜下百度分享不支持https的解决方案，有前辈做出解答。 其实，现在已经完成了；但是，为了折腾，我们接着来自定义百度分享的显示，点击代码获取，一步步进行定制，走完流程，点击直接获取代码，拿到一段js代码，类似如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;script&gt; window._bd_share_config = &#123; &quot;common&quot;: &#123; &quot;bdSnsKey&quot;: &#123;&#125;, &quot;bdText&quot;: &quot;&quot;, &quot;bdMini&quot;: &quot;2&quot;, &quot;bdMiniList&quot;: [ &quot;mshare&quot;, &quot;bdysc&quot;, &quot;evernotecn&quot;, &quot;tqq&quot;, &quot;weixin&quot;, &quot;sqq&quot;, &quot;qzone&quot;, &quot;douban&quot;, &quot;tsina&quot;, &quot;tieba&quot;, &quot;youdao&quot;, &quot;isohu&quot;, &quot;mail&quot;, &quot;ty&quot;, &quot;fbook&quot;, &quot;twi&quot;, &quot;linkedin&quot;, &quot;copy&quot;, &quot;print&quot; ], &quot;bdPic&quot;: &quot;&quot;, &quot;bdStyle&quot;: &quot;0&quot;, &quot;bdSize&quot;: &quot;16&quot; &#125;, &quot;slide&quot;: &#123; &quot;type&quot;: &quot;slide&quot;, &quot;bdImg&quot;: &quot;5&quot;, &quot;bdPos&quot;: &quot;right&quot;, &quot;bdTop&quot;: &quot;53.5&quot; &#125;, &quot;image&quot;: &#123; &quot;viewList&quot;: [ &quot;weixin&quot;, &quot;qzone&quot;, &quot;tsina&quot;, &quot;evernotecn&quot;, &quot;douban&quot;, &quot;bdysc&quot; ], &quot;viewText&quot;: &quot;分享到：&quot;, &quot;viewSize&quot;: &quot;16&quot; &#125;, &quot;selectShare&quot;: &#123; &quot;bdContainerClass&quot;: null, &quot;bdSelectMiniList&quot;: [ &quot;weixin&quot;, &quot;qzone&quot;, &quot;tsina&quot;, &quot;evernotecn&quot;, &quot;douban&quot;, &quot;bdysc&quot; ] &#125; &#125;;&lt;/script&gt; 最后，打开如下文件blog\themes\next\layout\_partials\share\baidushare.swing，替换掉里面的js代码，本文以slide模式为例，替换掉1&#123;% elseif theme.baidushare.type === &quot;slide&quot; %&#125; 后面的&lt;script&gt;...&lt;/script&gt;即可。 2017-05-17：markdown写文章时，添加居中引用模块 只需在写文章时，添加如下标签即可：123&lt;blockquote class=&quot;blockquote-center&quot;&gt; 优秀的人，不是不合群，而是他们合群的人里面没有你&lt;/blockquote&gt; 预览： 优秀的人，不是不合群，而是他们合群的人里面没有你 2017-05-16：首页文章预览添加图片 打开scaffolds/post.md文件，在默认参数中添加如下参数：1234# 首页文章预览添加图片：photos: - http://xxx.com/photo1.jpg - http://xxx.com/photo2.jpg 预览： 首页文章摘要模式 首页开启文章摘要模式，不全文显示，而是出现阅读全文&gt;，只需在主题配置文件中找到auto_excerpt属性进行配置12345# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: true #改写为true length: 150 #默认展示的高度 或者，在Markdown文章中不想显示的位置，添加如下代码：123这里显示&lt;!--more--&gt;这里不显示 预览：]]></content>
      <categories>
        <category>Notes</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-17 命运从不缺席]]></title>
    <url>%2F2017%2F05%2F17%2F2017-5-17-%E5%91%BD%E8%BF%90%E4%BB%8E%E4%B8%8D%E7%BC%BA%E5%B8%AD%2F</url>
    <content type="text"><![CDATA[优秀的人，不是不合群，而是他们合群的人里面没有你 纽约时间比加州时间早三个小时,New York is 3 hours ahead of California, 但加州时间并没有变慢。but it does not make California slow. 有人22岁就毕业了，Someone graduated at the age of 22, 但等了五年才找到好的工作！but waited 5 years before securing a good job! 有人25岁就当上CEO，Someone became a CEO at 25, 却在50岁去世。and died at 50. 也有人迟到50岁才当上CEO，While another became a CEO at 50, 然后活到90岁。and lived to 90 years. 有人依然单身，Someone is still single, 同时也有人已婚。while someone else got married.奥巴马55岁就退休，Obama retires at 55,` 川普70岁才开始当总统。but Trump starts at 70. 世上每个人本来就有自己的发展时区。Absolutely everyone in this world works based on their Time Zone. 身边有些人看似走在你前面，People around you might seem to go ahead of you, 也有人看似走在你后面。some might seem to be behind you. 但其实每个人在自己的时区有自己的步程。But everyone is running their own RACE, in their own TIME. 不用嫉妒或嘲笑他们。Don’t envy them or mock them. 他们都在自己的时区里，你也是！They are in their TIME ZONE, and you are in yours! 生命就是等待正确的行动时机。Life is about waiting for the right moment to act. 所以，放轻松。So, RELAX. 你没有落后。You’re not LATE. 你没有领先。You’re not EARLY. 在命运为你安排的属于自己的时区里，一切都准时。You are very much ON TIME, and in your TIME ZONE Destiny set up for you.]]></content>
      <categories>
        <category>Writings</category>
      </categories>
      <tags>
        <tag>美文</tag>
        <tag>励志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-16 从字典中提取子集]]></title>
    <url>%2F2017%2F05%2F16%2F2017-5-16-%E4%BB%8E%E5%AD%97%E5%85%B8%E4%B8%AD%E6%8F%90%E5%8F%96%E5%AD%90%E9%9B%86%2F</url>
    <content type="text"><![CDATA[需求给你一个条件，从已给字典中构造一个符合条件的新字典，为原字典的子集。 解决方案使用字典推导式： 123456789101112prices = &#123; 'ACME': 45.23, 'AAPL': 612.78, 'IBM': 205.55, 'HPQ': 37.20, 'FB': 10.75&#125;# Make a dictionary of all prices over 200p1 = &#123;key: value for key, value in prices.items() if value &gt; 200&#125;# Make a dictionary of tech stockstech_names = &#123;'AAPL', 'IBM', 'HPQ', 'MSFT'&#125;p2 = &#123;key: value for key, value in prices.items() if key in tech_names&#125; 案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# 需求：输出phone_bill中每月不为'0.00'的项目"phone_bill" : [ &#123; "bill_zengzhifei" : "0.00", "bill_qita" : "0.00", "bill_package" : "46.00", "bill_ext_sms" : "0.20", "bill_daishoufei" : "0.00", "bill_ext_data" : "0.00", "bill_ext_calls" : "0.00" &#125;, &#123; "bill_zengzhifei" : "0.00", "bill_qita" : "0.00", "bill_package" : "46.00", "bill_ext_sms" : "0.60", "bill_daishoufei" : "0.00", "bill_ext_data" : "15.62", "bill_ext_calls" : "4.18" &#125;, &#123; "bill_zengzhifei" : "0.00", "bill_qita" : "0.00", "bill_package" : "56.00", "bill_ext_sms" : "0.30", "bill_daishoufei" : "0.00", "bill_ext_data" : "9.36", "bill_ext_calls" : "7.03" &#125;, &#123; "bill_zengzhifei" : "0.00", "bill_qita" : "0.00", "bill_package" : "46.00", "bill_ext_sms" : "0.30", "bill_daishoufei" : "0.00", "bill_ext_data" : "0.00", "bill_ext_calls" : "0.00" &#125;, &#123; "bill_zengzhifei" : "0.00", "bill_qita" : "0.00", "bill_package" : "10.58", "bill_ext_sms" : "0.00", "bill_daishoufei" : "0.00", "bill_ext_data" : "0.00", "bill_ext_calls" : "0.00" &#125; ]# 处理逻辑for cursor in xrange(0,5): phone_bill_tmp = &#123;key: value[:-1] for key, value in phone_bill[cursor].items() if value not in ['','0.00']&#125; phone_bill.append(phone_bill_tmp)# 结果"phone_bill" : [ &#123; "bill_package" : "46.0", "bill_ext_sms" : "0.2" &#125;, &#123; "bill_package" : "46.0", "bill_ext_sms" : "0.6", "bill_ext_data" : "15.6", "bill_ext_calls" : "4.1" &#125;, &#123; "bill_package" : "56.0", "bill_ext_sms" : "0.3", "bill_ext_data" : "9.3", "bill_ext_calls" : "7.0" &#125;, &#123; "bill_package" : "46.0", "bill_ext_sms" : "0.3" &#125;, &#123; "bill_package" : "10.5" &#125; ] 思考大多数情况下字典推导能做到的，通过创建一个元组序列然后把它传给 dict() 函数也能实现。比如：1p1 = dict((key, value) for key, value in prices.items() if value &gt; 200) 但是，字典推导方式表意更清晰，并且实际上也会运行的更快些 (在这个p1中，实际测试几乎比 dcit() 函数方式快整整一倍)。 有时候完成同一件事会有多种方式。比如，p2程序也可以像这样重写：123# Make a dictionary of tech stockstech_names = &#123; 'AAPL', 'IBM', 'HPQ', 'MSFT' &#125;p2 = &#123; key:prices[key] for key in prices.keys() &amp; tech_names &#125; 但是，运行时间测试结果显示这种方案大概比第一种方案慢1.6倍。 所以，完成一个需求，方案并不是唯一的，也并没有最完美的，只有更好的解决方案，如果对程序运行性能要求比较高的话，这就需要花点时间去做计时测试了。]]></content>
      <categories>
        <category>Notes</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>字典推导式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-15 pandas-入门]]></title>
    <url>%2F2017%2F05%2F15%2F2017-5-15-pandas-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[数据结构12Series: 类似于一维数组的对象；索引（index）在左，数据（value）在右，索引自动创建DataFrame: 一种表格型数据结构；二维结构，每列可以存不同类型的值，索引包含行索引及列索引 创建Series12import pandas as pdser_obj = pd.Series(range(10, 20)) 获取数据及索引1234# 获取索引ser_obj.index# 获取数据ser_obj.values 通过索引获取数据1ser_obj[0]]]></content>
      <categories>
        <category>数据分析</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-5-15 数据分析 入门]]></title>
    <url>%2F2017%2F05%2F15%2F2017-5-15-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[DIKW体系1234D: Data 数据 原始素材I: Information 信息 加工处理后有逻辑的数据K: Knowledge 知识 提炼信息之间的联系，行动的能力，完成当下任务W: Wisdom 智慧 关心未来，具有预测的能力 数据工程1数据工程：一整套对数据（D）进行**采集**、处理、提取价值（变为I/K）的过程 职业划分12345Data Engineer 数据工程师 ：分析数据少不了需要运用计算机和各种工具自动化数据处理的过程， 包括数据格式转换， 储存， 更新， 查询。 数据工程师的工作就是开发工具完成自动化的过程， 属于 基础设施/工具（Infrastructure/Tools）层。但是这个角色出现的频率不多 ，因为有现成的MySQL, Oracle等数据库技术， 很多大公司只需要DBA就足够了。而 Hadoop, MongoDB 等 NoSQL 技术的开源， 更是使在大数据的场景下都没有太多 数据工程师 的事，一般都是交给 数据科学家 。Data Scientist 数据科学家 : 数据科学家是与数学相结合的中间角色， 需要用数学方法处理原始数据找出肉眼看不到的更高层数据， 一般是运用 统计机器学习（Statistical Machine Learning）或者 深度学习（Deep Learning）。有人称 Data Scientist 为 编程统计学家（Programming Statistician），因为他们需要有很好的统计学基础，但也需要参与程序的开发（基于 Infrastructure 之上），而现在很多很多的数据科学家 职位都要求身兼数据工程师。 数据科学家 是把 D 转为 I 或 K 的主力军。Data Analyst 数据分析师： 数据工程师和数据科学家做了大量的工作，用计算机程序尽可能多地提取了价值（I/K），然而真正要从数据中洞察出更高的价值， 则需要依靠丰富的行业经验和洞察力， 这些都需要人力的干预。Data Analyst 需要的是对所在业务有深刻了解， 能熟练运用手上的工具（无论是 Excel， SPSS也好， Python/R也好，工程师给你开发的工具也好，必要时还要能自己充当工程师和科学家，力尽所能得到自己需要的工具），有针对性地对数据作分析，并且需要把发现的成果向其他职能部门呈现出来，最终变为行动，这就是把数据最终得出 Wisdom。 数据分析1数据分析是指用适当的统计分析方法对收集来的大量数据进行分析，提取有用信息和形成结论而对数据加以详细研究和概括总结的过程。这一过程也是质量管理体系的支持过程。在实用中，数据分析可帮助人们作出判断，以便采取适当行动。 数据分析过程1234数据采集：本地数据或者网络数据的采集与操作。数据处理：数据的规整，按照某种格式进行整合存储。数据分析：数据的科学计算，使用相关数据工具进行分析。数据展现：数据可视化，使用相关工具对分析出的数据进行展示。 数据分析工具12345SAS:SAS（STATISTICAL ANALYSIS SYSTEM，简称SAS）公司开发的统计分析软件，是一个功能强大的数据库整合平台。价格昂贵，银行或者大企业才买的起，做离线的分析或者模型用。SPSS: SPSS（Statistical Product and Service Solutions，统计产品与服务解决方案）是IBM公司推出的一系列用于统计学分析运算、数据挖掘、预测分析和决策支持任务的产品，迄今已有40余年的成长历史，价格昂贵。R/MATLAB: 适合做学术性质的数据分析，在实际应用上需要额外转换为Python或Scala来实现，而且MATLAB（MathWorks公司出品的商业数学软件）是收费的。Scala：是一门函数式编程语言，熟练使用后开发效率较高，配合Spark适合大规模的数据分析和处理，Scala的运行环境是JVM。Python：Python在数据工程领域和机器学习领域有很多成熟的框架和算法库，完全可以只用Python就可以构建以数据为中心的应用程序。在数据工程领域和机器学习领域，Python非常非常流行。]]></content>
      <categories>
        <category>数据分析</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-05-07 Hexo 常用操作]]></title>
    <url>%2F2017%2F05%2F07%2F2017-5-7-Hexo-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[cyg操作1cd /cygdrive/d #切换到D盘 Hexo 操作12345678910111213hexo help # 查看帮助hexo version #查看Hexo的版本hexo algolia # 更新search庫hexo new "postName" #新建文章hexo new post "title" # 生成新文章：\source\_posts\title.md，可省略posthexo new page "pageName" #新建页面hexo clean #清除部署緩存hexo n == hexo new #新建文章hexo g == hexo generate #生成静态页面至public目录hexo s == hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）hexo d == hexo deploy #将.deploy目录部署到GitHubhexo d -g #生成加部署hexo s -g #生成加预览 *post、page等可以改成其他layout，可用layout在scaffolds目录下查看。在同目录下创建文件来添加自己的layout，也可以编辑现有的layout，比如post的layout默认是\scaffolds\post.md。 部署每次部署的步骤，可按以下两步来进行：12hexo clhexo d -g]]></content>
      <categories>
        <category>Notes</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
        <tag>速查</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-4-5 you are my sunshine!]]></title>
    <url>%2F2017%2F04%2F05%2F2017-4-5-you-are-my-sunshine%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F404.html</url>
    <content type="text"><![CDATA[404 L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"left","width":100,"height":200},"mobile":{"show":false},"log":false,"tagMode":false});]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fgoogle1c4a19302d3916a2.html</url>
    <content type="text"><![CDATA[google-site-verification: google1c4a19302d3916a2.html]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fabout%2Findex.html</url>
    <content type="text"><![CDATA[父母在，人生尚有來處；父母去，人生祗剩歸途。]]></content>
  </entry>
  <entry>
    <title><![CDATA[categories]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
